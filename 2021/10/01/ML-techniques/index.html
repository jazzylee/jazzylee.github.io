<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jazzylee.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.6.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="技法课围绕特征转换展开：  核变换&#x3D;&gt;SVM 特征融合&#x3D;&gt;AdaBoost 隐含特征&#x3D;&gt;Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习技法">
<meta property="og:url" content="https://jazzylee.github.io/2021/10/01/ML-techniques/index.html">
<meta property="og:site_name" content="北游记">
<meta property="og:description" content="技法课围绕特征转换展开：  核变换&#x3D;&gt;SVM 特征融合&#x3D;&gt;AdaBoost 隐含特征&#x3D;&gt;Deep Learning">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001171255314.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001172310596.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001173059632.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001174636361.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001174732735.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001175129048.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001175215667.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001175312155.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001205702245.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001214408848.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001214645047.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001215048974.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001215202200.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002142921388.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002143832939.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002165131756.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002165420115.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002165817984.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002171424011.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002171302914.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002184320109.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002183446341.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002184046736.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002184209009.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002185415862.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002185944016.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002191050002.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002191945483.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002192927526.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002193218480.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002193421450.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002193732062.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002194116544.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002195112604.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002195147120.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002195231862.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002195635381.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002200122832.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002200707174.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002201024988.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002201138232.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007162338291.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007162433775.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002203009631.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002204623820.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007163737168.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007163843357.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002214903450.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002215042895.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002215201907.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002215441487.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002220824708.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002215918286.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002220430085.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002221011426.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211002220551420.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003014442595.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003015334017.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007170115060.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003015550181.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003015748972.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007170910908.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020300298.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020709957.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020721913.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020732418.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020755142.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020821601.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020845711.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020949564.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003020957964.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003021029876.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003021439353.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007224048874.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007224151999.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007224407330.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003103123149.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003104737810.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003104956656.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003105443690.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003105701334.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003110034089.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003110419986.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003110537680.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003112501420.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003115320600.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007184554129.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007184609176.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007184834240.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007185356096.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007185758579.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007190641351.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007191111646.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003161510334.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003161826243.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003162128297.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003163802215.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211007193925062.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003192704890.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003192914495.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003193245392.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003194757575.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003194855315.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003195513468.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008200215555.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003200509780.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003200917741.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003201248556.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003201421768.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003201643368.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008201159108.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008202820997-16337082154092.png">
<meta property="og:image" content="file://E:\blog\myblog\source\_posts\ML-techniques\image-20211008203728213.png?lastModify=1633708718">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008204136981.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008204352302.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008204915411.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008212406227.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008213140018.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008213713813.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008213713813.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009010034056.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009010110646.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009010144803.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009010527061.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009010902457.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009010144803.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009011128205.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009012122892.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009012258703.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009012451404.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004185435760.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003224507689.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003224522400.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003224630368.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003224753539.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003230111096.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003230329499.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003230439799.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003231249907.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003231618809.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003232446892.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003232543725.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211003224630368.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004010642234.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004011257974.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009134238847.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009134337821.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009134418837.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009134712508.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004151955734.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004153458391.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004160946226.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004161345947.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004161418673.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004162020605.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004163400603.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009142540184.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004164134313.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009142945413.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004165542571.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004165716948.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004165854982.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004165955437.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004171000795.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004172227793.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004172345200.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004172508852.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004172622732.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004192621438.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004192830433.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211004193246485.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009153006501.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005111220437.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005111419399.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211009160437556.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005112120424.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005112314951.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005112755313.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005112816380.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005113556277.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211005113938452.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010123947967.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010124337518.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010124919588.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010124639641.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010124655301.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010125101108.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010125402631.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010125414821.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010133623800.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010132309170.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010132325827.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010134733682.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211006151940191.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010135831767.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010140000723.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010140418290.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010143126485.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010144423170.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010145207624.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010145236721.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010145430305.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010145543777.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010145933253.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010150105645.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010150331175.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008213713813.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008213713813.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010150700812.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010150907777.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010151312584.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010151437575.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010151736941.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211008213713813.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010152220339.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010152248279.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010152637257.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010152114738.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010153203553.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010153424575.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010161603389.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010161958941.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010162401608.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010163046766.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010164546334.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010180913446.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010170831208.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010170645590.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010170439560.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010182224020.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010183056496.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010203655217.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010204158861.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010204359506.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010204849506.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010205009152.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010205602421.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010205828741.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010210121573.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010210437894.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010211123750.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010210619242.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010210928120.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010211359352.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010194441711.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010194914623.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010195812289.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010200902181.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010201011512.png">
<meta property="og:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211010201807369.png">
<meta property="article:published_time" content="2021-10-01T06:42:49.000Z">
<meta property="article:modified_time" content="2021-10-13T03:10:00.895Z">
<meta property="article:author" content="movice">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jazzylee.github.io/2021/10/01/ML-techniques/image-20211001171255314.png">


<link rel="canonical" href="https://jazzylee.github.io/2021/10/01/ML-techniques/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jazzylee.github.io/2021/10/01/ML-techniques/","path":"2021/10/01/ML-techniques/","title":"机器学习技法"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习技法 | 北游记</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">北游记</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A0%B8%E5%8F%98%E6%8D%A2"><span class="nav-number">1.</span> <span class="nav-text">核变换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Linear-Support-Vector-Machine"><span class="nav-number">1.1.</span> <span class="nav-text">Linear Support Vector Machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%87%E5%87%86%E9%97%AE%E9%A2%98"><span class="nav-number">1.1.1.</span> <span class="nav-text">标准问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E6%A0%87%E5%87%86%E9%97%AE%E9%A2%98%E5%88%B0%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92"><span class="nav-number">1.1.2.</span> <span class="nav-text">从标准问题到二次规划</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVM%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AF%E4%BB%A5%E5%81%9A%E5%BE%97%E5%A5%BD%EF%BC%9F"><span class="nav-number">1.1.3.</span> <span class="nav-text">SVM为什么可以做得好？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dual-Support-Vector-Machine"><span class="nav-number">1.2.</span> <span class="nav-text">Dual Support Vector Machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98"><span class="nav-number">1.2.1.</span> <span class="nav-text">对偶问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98"><span class="nav-number">1.2.2.</span> <span class="nav-text">解对偶问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E5%88%B0%E8%BF%99%E9%87%8C%E7%BB%93%E6%9D%9F%E4%BA%86%E5%90%97"><span class="nav-number">1.2.3.</span> <span class="nav-text">问题到这里结束了吗?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernel-Support-Vector-Machine"><span class="nav-number">1.3.</span> <span class="nav-text">Kernel Support Vector Machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%8F%98%E6%8D%A2-1"><span class="nav-number">1.3.1.</span> <span class="nav-text">核变换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%A0%B8"><span class="nav-number">1.3.2.</span> <span class="nav-text">多项式核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%A0%B8-RBF%E6%A0%B8"><span class="nav-number">1.3.3.</span> <span class="nav-text">高斯核&#x2F;RBF核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E7%9A%84%E5%AF%B9%E6%AF%94%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="nav-number">1.3.4.</span> <span class="nav-text">核的对比与选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E8%AE%A1%E8%87%AA%E5%B7%B1%E7%9A%84Kernel-%E6%A0%B8%E7%9A%84%E5%85%85%E8%A6%81%E6%9D%A1%E4%BB%B6-Mercer%E2%80%99s-condition"><span class="nav-number">1.3.5.</span> <span class="nav-text">设计自己的Kernel-核的充要条件&#x2F;Mercer’s condition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Key-behind-Kernel-Trick-amp-Representer-Theorem"><span class="nav-number">1.3.6.</span> <span class="nav-text">Key behind Kernel Trick&amp;Representer Theorem</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Soft-Margin-Support-Vector-Machine"><span class="nav-number">1.4.</span> <span class="nav-text">Soft-Margin Support Vector Machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%98"><span class="nav-number">1.4.1.</span> <span class="nav-text">原始问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98-1"><span class="nav-number">1.4.2.</span> <span class="nav-text">对偶问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernel-Soft-Margin"><span class="nav-number">1.4.3.</span> <span class="nav-text">Kernel+Soft-Margin</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-number">1.4.4.</span> <span class="nav-text">模型选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kernel-logistic-regression"><span class="nav-number">1.5.</span> <span class="nav-text">Kernel logistic regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Soft-margin-SVM%E6%98%AF%E4%B8%80%E7%A7%8D%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="nav-number">1.5.1.</span> <span class="nav-text">Soft-margin SVM是一种正则化的方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hinge-error-measure"><span class="nav-number">1.5.2.</span> <span class="nav-text">hinge error measure</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVM-for-logistic-regression-soft-binary-classification"><span class="nav-number">1.5.3.</span> <span class="nav-text">SVM for logistic regression(soft binary classification)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#naive-idea1"><span class="nav-number">1.5.3.1.</span> <span class="nav-text">naive idea1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#naive-idea2"><span class="nav-number">1.5.3.2.</span> <span class="nav-text">naive idea2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#idea3-Probabilistic-SVM-Z%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3"><span class="nav-number">1.5.3.3.</span> <span class="nav-text">idea3-Probabilistic SVM(Z空间中的近似解)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Kernel-LogReg-%E5%9C%A8Z%E7%A9%BA%E9%97%B4%E5%81%9ALogReg"><span class="nav-number">1.5.3.4.</span> <span class="nav-text">Kernel LogReg-在Z空间做LogReg</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Support-Vector-Regression"><span class="nav-number">1.6.</span> <span class="nav-text">Support  Vector Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E5%BF%86ridge-regression"><span class="nav-number">1.6.1.</span> <span class="nav-text">回忆ridge regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kernel-ridge-regression"><span class="nav-number">1.6.2.</span> <span class="nav-text">kernel ridge regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kernel-ridge-regression%E5%81%9Aclassification-LSSVM-least-squares-SVM"><span class="nav-number">1.6.3.</span> <span class="nav-text">kernel ridge regression做classification-LSSVM(least-squares SVM)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tube-Regression"><span class="nav-number">1.6.4.</span> <span class="nav-text">Tube Regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernel%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93"><span class="nav-number">1.6.5.</span> <span class="nav-text">Kernel模型总结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Aggregation"><span class="nav-number">2.</span> <span class="nav-text">Aggregation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#blending-amp-bagging"><span class="nav-number">2.1.</span> <span class="nav-text">blending&amp;bagging</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#motivation"><span class="nav-number">2.1.1.</span> <span class="nav-text">motivation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uniform-blending"><span class="nav-number">2.1.2.</span> <span class="nav-text">Uniform blending</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-blending"><span class="nav-number">2.1.3.</span> <span class="nav-text">Linear blending</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Nonlinear-Any-blending-Stacking"><span class="nav-number">2.1.4.</span> <span class="nav-text">(Nonlinear) Any blending&#x2F;Stacking</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bootstrap-aggregating-Bagging"><span class="nav-number">2.1.5.</span> <span class="nav-text">Bootstrap aggregating(Bagging)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adaptive-boosting"><span class="nav-number">2.2.</span> <span class="nav-text">Adaptive boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Motivation"><span class="nav-number">2.2.1.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Re-weighting-by-bootstrapping"><span class="nav-number">2.2.2.</span> <span class="nav-text">Re-weighting by bootstrapping</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adaptive-Boosting-AdaBoost-Algorithm"><span class="nav-number">2.2.3.</span> <span class="nav-text">Adaptive Boosting(AdaBoost) Algorithm</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Decision-Tree"><span class="nav-number">2.3.</span> <span class="nav-text">Decision Tree</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Decision-Tree-Hypothesis"><span class="nav-number">2.3.1.</span> <span class="nav-text">Decision Tree Hypothesis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Basic-Decision-Tree-Algorithm-CART"><span class="nav-number">2.3.2.</span> <span class="nav-text">A Basic Decision Tree Algorithm-CART</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CART%E4%B8%AD%E7%9A%84Pruning"><span class="nav-number">2.3.3.</span> <span class="nav-text">CART中的Pruning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%90%86%E5%88%86%E6%94%AF"><span class="nav-number">2.3.4.</span> <span class="nav-text">决策树中的代理分支</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Random-Forest"><span class="nav-number">2.4.</span> <span class="nav-text">Random Forest</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Intro"><span class="nav-number">2.4.1.</span> <span class="nav-text">Intro</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Out-Of-Bag-Data-amp-self-validation"><span class="nav-number">2.4.2.</span> <span class="nav-text">Out Of Bag Data &amp; self validation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#random-test-amp-Feature-selection"><span class="nav-number">2.4.3.</span> <span class="nav-text">random test&amp;Feature selection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A6%81%E7%94%A8%E5%A4%9A%E5%B0%91%E6%A3%B5%E6%A0%91%EF%BC%9F"><span class="nav-number">2.4.4.</span> <span class="nav-text">要用多少棵树？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT"><span class="nav-number">2.5.</span> <span class="nav-text">GBDT</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9A%90%E5%90%AB%E7%89%B9%E5%BE%81"><span class="nav-number">3.</span> <span class="nav-text">隐含特征</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Neural-Network"><span class="nav-number">3.1.</span> <span class="nav-text">Neural Network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8Eperceptron%E5%88%B0MLP"><span class="nav-number">3.1.1.</span> <span class="nav-text">从perceptron到MLP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NN-hypothesis"><span class="nav-number">3.1.2.</span> <span class="nav-text">NN hypothesis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Optimization"><span class="nav-number">3.1.3.</span> <span class="nav-text">Optimization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularization"><span class="nav-number">3.1.4.</span> <span class="nav-text">Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-Learning"><span class="nav-number">3.1.5.</span> <span class="nav-text">Deep Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Intro-1"><span class="nav-number">3.1.6.</span> <span class="nav-text">Intro</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AutoEncoder-unsupervised-learning"><span class="nav-number">3.1.7.</span> <span class="nav-text">AutoEncoder-unsupervised learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularization-in-DL"><span class="nav-number">3.1.8.</span> <span class="nav-text">Regularization in DL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#linear-AutoEncoder-amp-PCA"><span class="nav-number">3.1.9.</span> <span class="nav-text">linear AutoEncoder&amp;PCA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#linear-AutoEncoder"><span class="nav-number">3.1.9.1.</span> <span class="nav-text">linear AutoEncoder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PCA-more-popular"><span class="nav-number">3.1.9.2.</span> <span class="nav-text">PCA(more popular)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RBF-Network"><span class="nav-number">3.2.</span> <span class="nav-text">RBF Network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RBF-hypothesis"><span class="nav-number">3.2.1.</span> <span class="nav-text">RBF hypothesis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RBF-Network-learning"><span class="nav-number">3.2.2.</span> <span class="nav-text">RBF Network learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Full-RBF-amp-Nearest-Neighbor"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">Full RBF&amp;Nearest Neighbor</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k-means"><span class="nav-number">3.2.3.</span> <span class="nav-text">k-means</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k-means-RBF"><span class="nav-number">3.2.4.</span> <span class="nav-text">k-means+RBF</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Matrix-Factorization"><span class="nav-number">3.3.</span> <span class="nav-text">Matrix Factorization</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Finale"><span class="nav-number">4.</span> <span class="nav-text">Finale</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#feature-exploitation-techniques"><span class="nav-number">4.1.</span> <span class="nav-text">feature exploitation techniques</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#error-optimization-techniques"><span class="nav-number">4.2.</span> <span class="nav-text">error optimization techniques</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#overfitting-eliminating-techniques"><span class="nav-number">4.3.</span> <span class="nav-text">overfitting eliminating techniques</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Machine-learning-in-practice"><span class="nav-number">4.4.</span> <span class="nav-text">Machine learning in practice</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">movice</p>
  <div class="site-description" itemprop="description">May the brave stay.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



          </div>
        </div>
    </div>
    <div>
      <!--clustrmaps-->
      <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=V7pseSmYqG3eRqg-m6VS1UxwXHXL8gIybqq7QtBtLug&cl=ffffff&w=a"></script>
    </div>
    <!--music-->
    <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=509720124&auto=0&height=66"></iframe>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jazzylee.github.io/2021/10/01/ML-techniques/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="movice">
      <meta itemprop="description" content="May the brave stay.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="北游记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习技法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-10-01 14:42:49" itemprop="dateCreated datePublished" datetime="2021-10-01T14:42:49+08:00">2021-10-01</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-10-13 11:10:00" itemprop="dateModified" datetime="2021-10-13T11:10:00+08:00">2021-10-13</time>
      </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>技法课围绕特征转换展开：</p>
<ul>
<li>核变换=&gt;SVM</li>
<li>特征融合=&gt;AdaBoost</li>
<li>隐含特征=&gt;Deep Learning</li>
</ul>
<span id="more"></span>

<h1 id="核变换"><a href="#核变换" class="headerlink" title="核变换"></a>核变换</h1><blockquote>
<p>software推荐(designed by NTU)：</p>
<p>liblinear：线性SVM</p>
<p>libsvm：对偶、核变换SVM</p>
</blockquote>
<h2 id="Linear-Support-Vector-Machine"><a href="#Linear-Support-Vector-Machine" class="headerlink" title="Linear Support Vector Machine"></a>Linear Support Vector Machine</h2><h3 id="标准问题"><a href="#标准问题" class="headerlink" title="标准问题"></a>标准问题</h3><img src="./image-20211001171255314.png" alt="image-20211001171255314" style="zoom: 50%;" />

<p>对于上图所示同样一笔线性可分的资料，如果超平面的margin越大，那么鲁棒性就越强 ，这里说的margin就是超平面与最近的样本点之间的距离，那么现在的任务就是最大化margin。</p>
<img src="./image-20211001172310596.png" alt="image-20211001172310596" style="zoom:50%;" />

<p>为了便于后续推导方便，将w0从以前熟悉的<em><strong>w</strong></em>向量中剥离出来，记为b，于是<em><strong>x</strong></em>中也省省掉了x0=1的项，假说h如下：</p>
<img src="./image-20211001173059632.png" alt="image-20211001173059632" style="zoom:50%;" />

<p>接下来回顾一下点到超平面的距离如何计算：</p>
<img src="./image-20211001174636361.png" alt="image-20211001174636361" style="zoom:50%;" />

<p>(<em><strong>w</strong></em>^T)<em><strong>x</strong></em>+b=0表示一个超平面，假设<code>x&#39;</code>和<code>x&#39;&#39;</code>是超平面上的两个点，即<code>(w^T)x&#39;=-b</code>，<code>(w^T)x&#39;&#39;=-b</code>，两者相减，<code>(w^T)(x&#39;-x‘’)=0</code>，<code>(x&#39;-x‘’)</code>是超平面上的向量，上式中内积为0，也就是说<code>(w^T)</code>是超平面的法向量。假设要计算平面外一点<code>x</code>到平面的距离，只要将<code>(x-x&#39;)</code>投影到单位化的<code>(w^T)</code>上，如下：</p>
<blockquote>
<p>投影，即内积，注意投影向量的单位化</p>
</blockquote>
<img src="./image-20211001174732735.png" alt="image-20211001174732735" style="zoom:50%;" />

<p>上面看的是任意的<em><strong>w</strong></em>，别忘了还有个条件没用：关心的是能将⭕和❌分开的<em><strong>w</strong></em>，即只要看能够使下面式子成立的<em><strong>w</strong></em>：</p>
<img src="./image-20211001175129048.png" alt="image-20211001175129048" style="zoom:50%;" />

<p>有了这个式子，上面的距离中就可以将绝对值拿掉了：</p>
<img src="./image-20211001175215667.png" alt="image-20211001175215667" style="zoom:50%;" />

<p>至此，最大化margin的问题描述如下：</p>
<img src="./image-20211001175312155.png" alt="image-20211001175312155" style="zoom: 50%;" />

<blockquote>
<p><strong>函数间隔与几何间隔 from 李航《统计学习方法》</strong></p>
<img src="./image-20211001205702245.png" alt="image-20211001205702245" style="zoom: 67%;" />

<p>观察图中ABC三个样本点，A距离超平面最远，若将其预测为正类，那么就比较确信结果是正确的；C距离超平面最近，将其预测为正类就不那么确信；B介于AC之间，将其预测成正类的确信度在A、C之间。</p>
<p>在超平面确定的情况下，|wx+b|的大小能够相对地表示点x与超平面的距离，<code>y(wx+b)</code>可以表示分类的正确性及确信度，这就是<font color='orange'>函数间隔</font>的概念。具体来说，<code>超平面</code>关于<code>样本点</code>的函数间隔就是<code>yi(wxi+b)</code>；<code>超平面</code>关于<code>样本集</code>的函数间隔就是在样本集中最小的关于样本点的函数间隔。<font color='red'>但是</font>，不同的w和b可能表示同一个超平面，所以同一个超平面(但w和b不同)与同一个样本点或者同一个样本集之间的函数间隔并不唯一。于是可以通过规范化的方式，得到几何间隔。</p>
<p>几何间隔就是本节开始部分的distance。</p>
</blockquote>
<p>接下来操作一下，对w和b增加一些要求，使得最小的函数间隔为1，就可以简化目标函数，详细参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42680622/article/details/106649564">这里</a>，此时要优化的问题描述如下：</p>
<img src="./image-20211001214408848.png" alt="image-20211001214408848" style="zoom:50%;" />

<p>这个条件中有最小化的操作，还是不太好解，尝试放宽一下条件，并证明条件放宽后的解依然和原来的相同，条件放松成下面的样子：</p>
<img src="./image-20211001214645047.png" alt="image-20211001214645047" style="zoom:50%;" />

<blockquote>
<p>可能会疑惑，这真的是放宽条件了吗，min=1和all≥1似乎是一样的？但实际上，all≥1的确是更宽松的条件，举个例子，min=2也在all≥1里面，但这时候原来的min=1已经不满足了。</p>
<p><strong>总结一句话：all≥1是min=1的<font color='orange'>必要条件</font></strong></p>
</blockquote>
<p>反证一下放松后的解依然ok：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果放宽条件后最佳的(b,w)会使得对于每一个n，yn乘以分数都大于1，例如都大于λ，那么放缩w和b，使新的w&#x27;=w/λ,新的b&#x27;=b/λ。这个时候依然满足宽松的条件，但是w/λ之后新的w变小了，1/||w||变大，也就是说刚刚最开始的w并非最佳解</span><br></pre></td></tr></table></figure>

<p>新的优化目标：</p>
<img src="./image-20211001215048974.png" alt="image-20211001215048974" style="zoom:50%;" />

<p>和下面的<font color='orange'>标准问题</font>是等价的：</p>
<img src="./image-20211001215202200.png" alt="image-20211001215202200" style="zoom:50%;" />

<h3 id="从标准问题到二次规划"><a href="#从标准问题到二次规划" class="headerlink" title="从标准问题到二次规划"></a>从标准问题到二次规划</h3><p>目标函数是二次式，所有的条件都是w和b的一次式=&gt;二次规划问题。二次规划问题有一套解法(调现成的函数就行)。</p>
<p>下面将SVM的标准问题描述成二次规划问题的标准形式：</p>
<img src="./image-20211002142921388.png" alt="image-20211002142921388" style="zoom:50%;" />

<p>两者对比一下，即可找到下面的的对应关系</p>
<img src="./image-20211002143832939.png" alt="image-20211002143832939" style="zoom:50%;" />

<p><strong>将这个问题交给二次规划工具来解，即可得到<em>w</em>和b</strong>，使用这个w和b，回传作为margin最大的g_svm。</p>
<h3 id="SVM为什么可以做得好？"><a href="#SVM为什么可以做得好？" class="headerlink" title="SVM为什么可以做得好？"></a>SVM为什么可以做得好？</h3><ol>
<li><p>直观上看，大的margin可以抵挡更大的测量误差</p>
<img src="./image-20211002165131756.png" alt="image-20211002165131756" style="zoom:50%;" /></li>
<li><p>SVM可以看作一种特殊的regularization：</p>
<img src="./image-20211002165420115.png" alt="image-20211002165420115" style="zoom:50%;" /></li>
<li><p>margin限制了dichotomy的数量，也就限制了VC维</p>
<img src="./image-20211002165817984.png" alt="image-20211002165817984" style="zoom:50%;" />

<p>概念上，演算法的VC维和数据有关：</p>
<img src="./image-20211002171424011.png" alt="image-20211002171424011" style="zoom:50%;" />

<blockquote>
<p>这个式子就不要求证明了。其中ρ表示margin</p>
</blockquote>
<p>举个例子，单位圆上有3个样本点：</p>
<img src="./image-20211002171302914.png" alt="image-20211002171302914" style="zoom:50%;" />

<p>不在意margin的时候，退化成原始的二维感知机，d_vc=3；</p>
<p>单位圆的内接正三角形边长为√3，如果这时候要求margin&gt;√3/2，是做不到的，即无法shatter3个点，d_vc&lt;3。</p>
</li>
</ol>
<hr>

<p>SVM中对VC维又加上了一层限制，泛化能力更好(<font color='orange'>更小的VC维</font>)，如果再加上后面要学的非线性特征变换，可以使VC维在不是很大的情况下得到复杂的边界(<font color='orange'>更小的Ein</font>)。</p>
<h2 id="Dual-Support-Vector-Machine"><a href="#Dual-Support-Vector-Machine" class="headerlink" title="Dual Support Vector Machine"></a>Dual Support Vector Machine</h2><h3 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h3><p>引入特征变换之后，SVM问题重新描述成下面的样子，有<img src="./image-20211002184320109.png" alt="image-20211002184320109" style="zoom: 40%;" />个变量，N个约束：</p>
<img src="./image-20211002183446341.png" alt="image-20211002183446341" style="zoom:50%;" />

<p>其中，b是实数，w的维度是新空间的维度，用<img src="./image-20211002184046736.png" alt="image-20211002184046736" style="zoom:50%;" />表示，那么为了表达成标准的二次规划问题，几个量及其维度如下：</p>
<img src="./image-20211002184209009.png" alt="image-20211002184209009" style="zoom:50%;" />

<p><code>TODO</code>:接下来尝试解一个只有N个变量，有N+1个约束的SVM问题，称为原始问题的<font color='orange'>对偶问题</font>，这涉及最优化相关的知识</p>
<blockquote>
<p>Math warning!!!非专业人士已经在撤离了QWQ</p>
</blockquote>
<p><code>Lagrange</code>:以前经常用λ作为乘子，在SVM中使用α表示乘子，将条件加到式子中：</p>
<img src="./image-20211002185415862.png" alt="image-20211002185415862" style="zoom:50%;" />

<p>SVM问题到现在变成了下面的样子：</p>
<blockquote>
<p>intuitive proof：P6 12:30</p>
</blockquote>
<img src="./image-20211002185944016.png" alt="image-20211002185944016" style="zoom:50%;" />

<p>对于任意的一个α’，上式中内部max的部分都要大于L(b,w,α’)，也就是说对任意的α’来说，都有：</p>
<img src="./image-20211002191050002.png" alt="image-20211002191050002" style="zoom:50%;" />

<p>对于每一个不同的α’来说，min L(b,w,α’)都是不一样的，但是上式对任意的α’都成立，因此找一个能使min L(b,w,α’)最大的出来也成立：</p>
<img src="./image-20211002191945483.png" alt="image-20211002191945483" style="zoom:50%;" />

<p>跳过中间的分析过程，这里就是把min和max交换了位置，叫做<font color='orange'>Lagrange对偶问题</font>。如果有强对偶的关系，那么就可以解右边的式子，式中最小化L(b,w,α)时，没有顾虑。</p>
<blockquote>
<p>≥：弱对偶</p>
<p><font color='orange'>=：强对偶</font></p>
<p><code>claim</code>:如果QP是凸的、有解的(征变换后<strong>线性可分</strong>)、约束是线性的(这点是显然的)，那么就是<font color='orange'>强对偶</font>的，解左边和解右边都一样。</p>
</blockquote>
<p>下面的任务就是解对偶的问题：</p>
<img src="./image-20211002192927526.png" alt="image-20211002192927526" style="zoom:50%;" />

<p>内部的最小化问题没有条件限制，最小的时候，L对b和w的偏微分都应该是0：</p>
<ul>
<li><p>L对b的偏微分是0：</p>
<img src="./image-20211002193218480.png" alt="image-20211002193218480" style="zoom:50%;" />

<p>有了这个条件，上面要解的问题中b的部分就为0了，式子就和b无关了，这 时L写成了下面的样子：</p>
<img src="./image-20211002193421450.png" alt="image-20211002193421450" style="zoom:50%;" /></li>
<li><p>上面的L对w的偏微分是0，可以得到下面的结果：</p>
<img src="./image-20211002193732062.png" alt="image-20211002193732062" style="zoom:50%;" />

<p>再将这个条件加到最优化的式子中，可以进行进一步的简化，简化之后，原始的max min问题变成了对α的最大化问题：</p>
<img src="./image-20211002194116544.png" alt="image-20211002194116544" style="zoom:50%;" /></li>
</ul>
<p>在得到了α之后，如何计算b和w呢？解出了w之后，对b和w有一些限制，叫做<code>KKT条件</code>，使用这些限制即可得到b和w：</p>
<blockquote>
<p><code>claim KKT:</code></p>
<p>如果一组(α,b,w)在原始问题及对偶问题中都是最佳解，要满足下面的式子:</p>
<ol>
<li><p>满足原始问题的条件：</p>
<img src="./image-20211002195112604.png" alt="image-20211002195112604" style="zoom:50%;" /></li>
<li><p>满足对偶问题的条件：</p>
<img src="./image-20211002195147120.png" alt="image-20211002195147120" style="zoom:50%;" /></li>
<li><p>两个偏微分是0：</p>
<img src="./image-20211002195231862.png" alt="image-20211002195231862" style="zoom:50%;" /></li>
<li><p>complementary slackness：</p>
<img src="./image-20211002195635381.png" alt="image-20211002195635381" style="zoom:50%;" /></li>
</ol>
</blockquote>
<p>再来看下KKT条件的最后一条，两者必有一个为0。如果α&gt;0，点zn一定在边界上，这类点叫做<font color='orange'>支撑向量</font>Support Vector。这样，所有的样本点就可以分成三类</p>
<blockquote>
<p>普通点</p>
<blockquote>
<p>支撑向量候选(位于边界上)</p>
<blockquote>
<p>支撑向量(α&gt;0)</p>
</blockquote>
</blockquote>
</blockquote>
<h3 id="解对偶问题"><a href="#解对偶问题" class="headerlink" title="解对偶问题"></a>解对偶问题</h3><p>把最大化的问题换成习惯的最小化的问题：</p>
<img src="./image-20211002200122832.png" alt="image-20211002200122832" style="zoom:50%;" />

<blockquote>
<p>claim：这是一个凸的QP问题，有N个变量，N+1个条件</p>
</blockquote>
<p>将上面的问题写成标准的QP形式：</p>
<img src="./image-20211002200707174.png" alt="image-20211002200707174" style="zoom:50%;" />

<blockquote>
<p>注意一下Q矩阵的shape，是N*N的稠密矩阵，N=30000时，Q矩阵要消耗3GB RAM…QAQ</p>
</blockquote>
<p>调用一下QP的工具，就可以得到α了。有了α之后，结合前面提到的KKT条件，得到b和w：</p>
<ul>
<li><p>w：<img src="./image-20211002201024988.png" alt="image-20211002201024988" style="zoom:50%;" /></p>
</li>
<li><p>b：只要存在一个非零的α(意味着点在边界上)，就可以使用complementary slackness条件得到b，</p>
<img src="./image-20211002201138232.png" alt="image-20211002201138232" style="zoom:50%;" /></li>
</ul>
<p><code>Note:w和b都可以只用Support Vector表示出来</code></p>
<blockquote>
<p>α&gt;0那部分在边界上的点叫做Support Vector。<br>再看一下w，w是用α对ynzn的线性组合，意味着w可以只使用在边界上的点来表示；</p>
<img src="./image-20211007162338291.png" alt="image-20211007162338291" style="zoom:50%;" />

<p>计算b的时候，也是只需要找一个在边界上点</p>
<img src="./image-20211007162433775.png" alt="image-20211007162433775" style="zoom:50%;" />
</blockquote>
<h3 id="问题到这里结束了吗"><a href="#问题到这里结束了吗" class="headerlink" title="问题到这里结束了吗?"></a>问题到这里结束了吗?</h3><p>原始SVM和对偶SVM分别总结如下，原始SVM变量的数量与特征转换有关，对偶SVM问题中，变量的数量是资料量N</p>
<img src="./image-20211002203009631.png" alt="image-20211002203009631" style="zoom:50%;" />

<p>但是对偶SVM中，计算Q矩阵时涉及z向量的计算，z的维数仍是是很大的:</p>
<img src="./image-20211002204623820.png" alt="image-20211002204623820" style="zoom:50%;" />

<p>接下来的任务是找到一种方法，避开高维内积的计算</p>
<h2 id="Kernel-Support-Vector-Machine"><a href="#Kernel-Support-Vector-Machine" class="headerlink" title="Kernel Support Vector Machine"></a>Kernel Support Vector Machine</h2><h3 id="核变换-1"><a href="#核变换-1" class="headerlink" title="核变换"></a>核变换</h3><p>前面小节中，zn和zm是原始空间中的资料映射到高维空间中的结果，由于特征空间维数可能很高，直接计算通常是困难的，为了避开这个障碍，可以设想这样一个函数：</p>
<table>
<thead>
<tr>
<th align="center">k(xi,xj)=&lt;Φ(xi),Φ(xj)&gt;</th>
</tr>
</thead>
</table>
<p>即xi与xj在特征空间的内积等于它们在原始原始样本空间中通过函数k(·)计算出的结果，其中k(·)就是<font color='orange'>核函数</font>。</p>
<hr>

<p>以(灌水的)二次变换为例子，</p>
<img src="./image-20211007163737168.png" alt="image-20211007163737168" style="zoom:50%;" />

<p>先变换再内积可以将时间复杂度从O(d^2)降到O(d)：</p>
<img src="./image-20211007163843357.png" alt="image-20211007163843357" style="zoom:50%;" />

<hr>

<p>核函数在SVM中可以简化哪些计算呢？</p>
<ol>
<li>Q矩阵的每一项：<img src="./image-20211002214903450.png" alt="image-20211002214903450" style="zoom:50%;" /></li>
<li>b的计算：<img src="./image-20211002215042895.png" alt="image-20211002215042895" style="zoom:33%;" /></li>
<li>回传g_svm之后，使用它对新的资料做分类：<img src="./image-20211002215201907.png" alt="image-20211002215201907" style="zoom: 33%;" /></li>
</ol>
<p>总计一下引入核变换之后的SVM：</p>
<img src="./image-20211002215441487.png" alt="image-20211002215441487" style="zoom:50%;" />

<h3 id="多项式核"><a href="#多项式核" class="headerlink" title="多项式核"></a>多项式核</h3><ul>
<li><p>线性核(没做转换)<img src="./image-20211002220824708.png" alt="image-20211002220824708" style="zoom:50%;" /></p>
<blockquote>
<p>linear first :-)</p>
</blockquote>
</li>
<li><p>二次多项式核<img src="./image-20211002215918286.png" alt="image-20211002215918286" style="zoom:50%;" /></p>
</li>
<li><p>通用的二次多项式核 <img src="./image-20211002220430085.png" alt="image-20211002220430085" style="zoom:50%;" /></p>
<p>变换如下：<img src="./image-20211002221011426.png" alt="image-20211002221011426" style="zoom:50%;" /></p>
</li>
<li><p>通用的Q次多项式核<img src="./image-20211002220551420.png" alt="image-20211002220551420" style="zoom:50%;" /></p>
</li>
</ul>
<p>到这里，再重新审视一下核函数。核函数K(·)直接得到了两个样本点在变换到高维空间后的内积，降低了运算量。接下来一小节将看到：把特征变换藏在kernel里，不需要再显式写出变换的函数。</p>
<blockquote>
<p>kernel代表两笔x转换后在Z空间中的相似性。</p>
</blockquote>
<h3 id="高斯核-RBF核"><a href="#高斯核-RBF核" class="headerlink" title="高斯核/RBF核"></a>高斯核/RBF核</h3><p>尝试使用高效的核函数将特征变换到无限维的空间。</p>
<p>x只有一个维度的时候(单纯是为了书写上的方便)，高斯核函数如下：</p>
<img src="./image-20211003014442595.png" alt="image-20211003014442595" style="zoom:50%;" />

<p>不嫌烦的话，可以借助泰勒公式将其展开，剥离出特征变换的式子：</p>
<img src="./image-20211003015334017.png" alt="image-20211003015334017" style="zoom:50%;" />

<p>剥离的无限维转换函数如下：</p>
<img src="./image-20211007170115060.png" alt="image-20211007170115060" style="zoom:50%;" />

<p>generally，高斯核如下表示：</p>
<img src="./image-20211003015550181.png" alt="image-20211003015550181" style="zoom:50%;" />

<p>进而可以写出高斯核下的g_svm,它是中心在SV上的高斯函数的线性组合:</p>
<img src="./image-20211003015748972.png" alt="image-20211003015748972" style="zoom:50%;" />

<blockquote>
<p>仔细看，有没有看到Nueral Network的影子？:-）</p>
<img src="./image-20211007170910908.png" alt="image-20211007170910908" style="zoom:50%;" />
</blockquote>
<p>至于为什么叫RBF核(Radial Basis Function Kernel)：</p>
<ul>
<li>Radial：从中心向外辐射</li>
<li>Basis Function：拿来做线性组合</li>
</ul>
<p>拉出来遛遛：</p>
<p><img src="./image-20211003020300298.png" alt="image-20211003020300298"></p>
<blockquote>
<p>大的γ=&gt;尖的Gaussian=&gt;overfit，不建议使用太大的γ</p>
</blockquote>
<h3 id="核的对比与选择"><a href="#核的对比与选择" class="headerlink" title="核的对比与选择"></a>核的对比与选择</h3><ul>
<li>linear first</li>
<li>多项式核-小Q情况</li>
<li>高斯核-最常用，注意overfit的问题</li>
</ul>
<table>
<thead>
<tr>
<th align="center">核</th>
<th align="center">核函数</th>
<th align="center">pros</th>
<th align="center">cons</th>
</tr>
</thead>
<tbody><tr>
<td align="center">线性核(不做转换)</td>
<td align="center"><img src="./image-20211003020709957.png" alt="image-20211003020709957" style="zoom:50%;" /></td>
<td align="center"><img src="./image-20211003020721913.png" alt="image-20211003020721913" style="zoom:50%;" /></td>
<td align="center"><img src="./image-20211003020732418.png" alt="image-20211003020732418" style="zoom:50%;" /></td>
</tr>
<tr>
<td align="center">多项式核</td>
<td align="center"><img src="./image-20211003020755142.png" alt="image-20211003020755142" style="zoom:50%;" /></td>
<td align="center"><img src="./image-20211003020821601.png" alt="image-20211003020821601" style="zoom:50%;" /></td>
<td align="center"><img src="./image-20211003020845711.png" alt="image-20211003020845711" style="zoom:50%;" /></td>
</tr>
<tr>
<td align="center">高斯核</td>
<td align="center"><img src="./image-20211003020949564.png" alt="image-20211003020949564" style="zoom:50%;" /></td>
<td align="center"><img src="./image-20211003020957964.png" alt="image-20211003020957964" style="zoom:50%;" /></td>
<td align="center"><img src="./image-20211003021029876.png" alt="image-20211003021029876" style="zoom:50%;" /></td>
</tr>
</tbody></table>
<h3 id="设计自己的Kernel-核的充要条件-Mercer’s-condition"><a href="#设计自己的Kernel-核的充要条件-Mercer’s-condition" class="headerlink" title="设计自己的Kernel-核的充要条件/Mercer’s condition"></a>设计自己的Kernel-核的充要条件/Mercer’s condition</h3><ol>
<li><p>对称</p>
</li>
<li><p>如下的K矩阵半正定</p>
<img src="./image-20211003021439353.png" alt="image-20211003021439353" style="zoom:50%;" /></li>
</ol>
<h3 id="Key-behind-Kernel-Trick-amp-Representer-Theorem"><a href="#Key-behind-Kernel-Trick-amp-Representer-Theorem" class="headerlink" title="Key behind Kernel Trick&amp;Representer Theorem"></a>Key behind Kernel Trick&amp;Representer Theorem</h3><p>kernel trick：</p>
<img src="./image-20211007224048874.png" alt="image-20211007224048874" style="zoom:50%;" />

<p>把z的内积换成在X空间中便于计算的函数。回传一个z的加权和(即w^T·z)的时候，如果w能够表示成z的线性组合，那么就能work。</p>
<hr>

<p>SVM中最佳的w就是一堆z的线性组合；PLA的w也是z的线性组合；LogReg的w也是z的线性组合</p>
<img src="./image-20211007224151999.png" alt="image-20211007224151999" style="zoom:50%;" />

<p>形如下面的L2正则化的问题，最好的w可以表示为z的线性组合</p>
<img src="./image-20211007224407330.png" alt="image-20211007224407330" style="zoom:50%;" />

<h2 id="Soft-Margin-Support-Vector-Machine"><a href="#Soft-Margin-Support-Vector-Machine" class="headerlink" title="Soft-Margin Support Vector Machine"></a><font color='orange'>Soft-Margin Support Vector Machine</font></h2><h3 id="原始问题"><a href="#原始问题" class="headerlink" title="原始问题"></a>原始问题</h3><p>还记得贪心的Pocket吗？最小化犯错的数量。</p>
<p>在SVM的标准问题中引入类似的想法，最小化犯错的数量，其中C是margin和noise tolerance的tradeoff，<font color='orange'>C大，越希望少犯错；C小，犯点错误没关系，margin大一些。</font></p>
<img src="./image-20211003103123149.png" alt="image-20211003103123149" style="zoom:50%;" />

<p>但是上述的优化目标带来了两个问题：</p>
<ol>
<li>问题不再是QP问题</li>
<li>SVM中，可以想象不同出错点的影响不该是一样的。分类错误的时候，离超平面越远，错误应该是越不能忍受的</li>
</ol>
<p>如果要tradeoff的不是犯了几个错误，而是犯了多大的错误呢？👇</p>
<p>使用ξn记录第n个样本点犯了多大的错误(ξ≥0) ，于是又变成了QP问题：</p>
<img src="./image-20211003104737810.png" alt="image-20211003104737810" style="zoom:50%;" />

<p>在这个目标中，一共有<img src="./image-20211003104956656.png" alt="image-20211003104956656" style="zoom:33%;" />个变量(1个b，N个犯错情况，以及剩下的w)，有2N个条件。</p>
<h3 id="对偶问题-1"><a href="#对偶问题-1" class="headerlink" title="对偶问题"></a>对偶问题</h3><p>lagrange函数：</p>
<img src="./image-20211003105443690.png" alt="image-20211003105443690" style="zoom:50%;" />

<p>对偶问题：</p>
<img src="./image-20211003105701334.png" alt="image-20211003105701334" style="zoom:50%;" />

<p>L对三个变量的偏微分是0。</p>
<p>先来看看对ξn的偏微分为0=&gt;得到βn+αn=C。又因为乘子都是非负的，下面可以将βn直接表示成C-αn，且αn在[0,C]之间</p>
<img src="./image-20211003110034089.png" alt="image-20211003110034089" style="zoom:50%;" />

<p>使用β=C-α代换之后，神奇的事情发生了，有一坨东西(包括ξn)被消掉了：</p>
<blockquote>
<p>SVM再一次展现出其漂亮的数学原理</p>
</blockquote>
<img src="./image-20211003110419986.png" alt="image-20211003110419986" style="zoom:50%;" />

<p>写得清爽一些：</p>
<img src="./image-20211003110537680.png" alt="image-20211003110537680" style="zoom:50%;" />

<p>这个问题和hard margin的lagrange对偶问题几乎一样，只是max时候的条件有点区别。</p>
<p>然后分别计算对b和w的偏微分，令其为0。</p>
<p>最后可以得到soft margin下的优化目标，有N个变量，2N+1个关于α的条件：</p>
<img src="./image-20211003112501420.png" alt="image-20211003112501420" style="zoom:50%;" />

<h3 id="Kernel-Soft-Margin"><a href="#Kernel-Soft-Margin" class="headerlink" title="Kernel+Soft-Margin"></a>Kernel+Soft-Margin</h3><img src="./image-20211003115320600.png" alt="image-20211003115320600" style="zoom:50%;" />

<p>KKT的条件变了，这时候b怎么算？</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">hard-margin</th>
<th align="center">soft-margin</th>
</tr>
</thead>
<tbody><tr>
<td align="center">complementary slackness</td>
<td align="center"><img src="./image-20211007184554129.png" alt="image-20211007184554129" style="zoom:50%;" /></td>
<td align="center"><img src="./image-20211007184609176.png" alt="image-20211007184609176" style="zoom:50%;" /></td>
</tr>
<tr>
<td align="center">b=?</td>
<td align="center">使用SV确定b：<br><img src="./image-20211007184834240.png" alt="image-20211007184834240" style="zoom: 50%;" /></td>
<td align="center">使用free的SV确定b：<br><img src="./image-20211007185356096.png" alt="image-20211007185356096" style="zoom:50%;" /></td>
</tr>
<tr>
<td align="center">Note</td>
<td align="center"></td>
<td align="center">free指的是αn&lt;C的点(即ξn=0的点)。极少数的情况下找不到free SV，那么b不唯一，由不等式确定</td>
</tr>
</tbody></table>
<p>拉出来遛遛</p>
<img src="./image-20211007185758579.png" alt="image-20211007185758579" style="zoom:50%;" />

<p>kernel soft margin把点分为三类：</p>
<ul>
<li><p>non SV：αn=0，ξn=0=&gt;边界之外没有犯错的点</p>
</li>
<li><p>free SV：0&lt;αn&lt;C,ξn=0,在边界上的点</p>
</li>
<li><p>bounded SV：αn=C，ξn≠0，犯错的点，犯的错误为：</p>
<img src="./image-20211007190641351.png" alt="image-20211007190641351" style="zoom:50%;" /></li>
</ul>
<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><ol>
<li><p>使用Dval选择</p>
</li>
<li><p>根据SV数量选择模型</p>
<blockquote>
<p>claim：leave one out cross validation error与SV的数量有关：</p>
<img src="./image-20211007191111646.png" alt="image-20211007191111646" style="zoom:50%;" /></blockquote>
</li>
</ol>
<h2 id="Kernel-logistic-regression"><a href="#Kernel-logistic-regression" class="headerlink" title="Kernel logistic regression"></a>Kernel logistic regression</h2><h3 id="Soft-margin-SVM是一种正则化的方式"><a href="#Soft-margin-SVM是一种正则化的方式" class="headerlink" title="Soft-margin SVM是一种正则化的方式"></a>Soft-margin SVM是一种正则化的方式</h3><p>soft-margin SVM中犯的错误ξn其实可以写成下面的式子(ξn是b和w作用下的结果)：</p>
<img src="./image-20211003161510334.png" alt="image-20211003161510334" style="zoom:50%;" />

<p>在margin之外的“安全地区”时，也就是yn·score&gt;1时，犯的错误为0，在margin之内时，计算犯了多少的错误。这时SVM可以写成下面的样子，</p>
<img src="./image-20211003161826243.png" alt="image-20211003161826243" style="zoom:50%;" />

<p>还记得L2正则化吗？<code>min(Ein+w_reg)</code>，对比看一下上面的式子，SVM后面那部分对应着L2式子中的错误项。所以，soft-margin SVM就是一种regularization的实现，表示可以找到的hyper plane可能比较少</p>
<img src="./image-20211003162128297.png" alt="image-20211003162128297" style="zoom:50%;" />

<p>两个问题很像，为什么不从正规化的角度出发解这个问题呢？</p>
<ul>
<li>非QP</li>
<li>max部分不可微</li>
</ul>
<h3 id="hinge-error-measure"><a href="#hinge-error-measure" class="headerlink" title="hinge error measure"></a>hinge error measure</h3><p>再回头看一看soft-margin的目标函数，max的部分，也就是ξn，叫做铰链损失，和0/1 err以及scaled ce err对比如下：</p>
<img src="./image-20211003163802215.png" alt="image-20211003163802215" style="zoom:50%;" />

<p>正则化的LogReg几乎是在做SVM，反过来看，SVM更像是在做有正规化的logistic regression。大胆一点，能不能通过解一个soft margin SVM的问题得到w和b，并将其用在logistic regression中？下回分解。</p>
<h3 id="SVM-for-logistic-regression-soft-binary-classification"><a href="#SVM-for-logistic-regression-soft-binary-classification" class="headerlink" title="SVM for logistic regression(soft binary classification)"></a>SVM for logistic regression(soft binary classification)</h3><h4 id="naive-idea1"><a href="#naive-idea1" class="headerlink" title="naive idea1"></a>naive idea1</h4><p>使用SVM得到w和b，当作LogReg的近似解，返回如下的g：</p>
<img src="./image-20211007193925062.png" alt="image-20211007193925062" style="zoom:50%;" />

<p>表现还不错，但是<font color='red'>丧失了LogReg中的Maximum Likelihood</font>等结果。</p>
<h4 id="naive-idea2"><a href="#naive-idea2" class="headerlink" title="naive idea2"></a>naive idea2</h4><p>使用SVM获得w和b，并作为LogReg的初始值，跑LogReg。</p>
<p>但是这丧失了SVM的flavor</p>
<h4 id="idea3-Probabilistic-SVM-Z空间中的近似解"><a href="#idea3-Probabilistic-SVM-Z空间中的近似解" class="headerlink" title="idea3-Probabilistic SVM(Z空间中的近似解)"></a>idea3-Probabilistic SVM(Z空间中的<font color='orange'>近似解</font>)</h4><p>是一个两阶段(two-stage)的方式：SVM做特征转换+LogReg。可以获得Z空间中的<font color='orange'>近似解</font>。</p>
<p>按照下面的方式结合SVM和logistic regression：</p>
<img src="./image-20211003192704890.png" alt="image-20211003192704890" style="zoom:50%;" />

<blockquote>
<p>下面在说什么啊QWQ（P20 5:30）</p>
<p><font color='red'>使用SVM找w和b，于是就确定了超平面的方向；</font></p>
<p>使用A和B取微调超平面，如果SVM找的超平面是还不错的，那么A应该是正数，B应该接近0</p>
</blockquote>
<p>把θ函数展开写成下面的样子：</p>
<img src="./image-20211003192914495.png" alt="image-20211003192914495" style="zoom:50%;" />

<p>SVM找到w和b之后，再给定一个样本点，就可以得到样本点的score，相当于是对于每个样本点，使用SVM做了一个从高维到一维的转换；</p>
<blockquote>
<p>又看到了NN的影子:-)</p>
</blockquote>
<p>有了转换的值之后，再跑一下logistic regression做微调(例如可以使用GD等算法)，最后回传的g如下：</p>
<img src="./image-20211003193245392.png" alt="image-20211003193245392" style="zoom:50%;" />

<h4 id="Kernel-LogReg-在Z空间做LogReg"><a href="#Kernel-LogReg-在Z空间做LogReg" class="headerlink" title="Kernel LogReg-在Z空间做LogReg"></a>Kernel LogReg-在Z空间做LogReg</h4><blockquote>
<p>回忆一下前面的表示学习claim：</p>
<p>对于任意一个L2 regularized的问题，最优的w一定可以表示成原始资料的线性组合</p>
</blockquote>
<p>为了把Kernel用在LogReg中，加个L2正则。L2-regularized logistic regression问题描述如下：</p>
<img src="./image-20211003194757575.png" alt="image-20211003194757575" style="zoom:50%;" />

<p>这样w就一定是一堆z的线性组合，那么下面直接解一个对线性组合的<strong>系数</strong>最优化的问题好了：</p>
<img src="./image-20211003194855315.png" alt="image-20211003194855315" style="zoom:50%;" />

<blockquote>
<p>再现类NN的模型</p>
</blockquote>
<blockquote>
<p>另一种视角：<strong>β的线性模型</strong></p>
<img src="./image-20211003195513468.png" alt="image-20211003195513468" style="zoom:50%;" />

<p>Kernel是一种相似性，β扮演的是N维空间中w的角色。</p>
<p>前面的双重求和是一种含有K的特殊的正则项</p>
</blockquote>
<p>kernel logistic regression(KLR)</p>
<ul>
<li>w的线性模型，作用在核变换之后的空间。维度大；外加一个L2正则项</li>
<li>β的线性模型，作用在用kernel转换的资料上，维度小；外加一个特殊的正则项</li>
</ul>
<h2 id="Support-Vector-Regression"><a href="#Support-Vector-Regression" class="headerlink" title="Support  Vector Regression"></a>Support  Vector Regression</h2><h3 id="回忆ridge-regression"><a href="#回忆ridge-regression" class="headerlink" title="回忆ridge regression"></a>回忆ridge regression</h3><p>ridge regression就是在linear regression上加了L2正则项。而在前面的representer theorem了解到，加了L2正则的线性模型中，最好的w可以用z的线性组合表示：</p>
<img src="./image-20211008200215555.png" alt="image-20211008200215555" style="zoom:50%;" />

<p>LinReg和ridge regression都有解析解(analytical solution)，本节讨论的是如何把kernel trick用到linear regression中进而实现non-linear regression？</p>
<h3 id="kernel-ridge-regression"><a href="#kernel-ridge-regression" class="headerlink" title="kernel ridge regression"></a>kernel ridge regression</h3><p>问题表述如下：</p>
<img src="./image-20211003200509780.png" alt="image-20211003200509780" style="zoom:50%;" />

<p>将w用z的线性组合代换，将对w的最优化问题变成对β的最优化问题：</p>
<img src="./image-20211003200917741.png" alt="image-20211003200917741" style="zoom:50%;" />

<p>这还可以看成是β的线性模型，前面可以看成是与K有关的β的正则项，后面是β作用在kernel转换出来的资料上。如何解最好的β？这是个无条件的最优化问题，算梯度：</p>
<blockquote>
<p>K是对称的，为了下面方便，写成K转置，I也是偷偷塞进去的</p>
</blockquote>
<img src="./image-20211003201248556.png" alt="image-20211003201248556" style="zoom:50%;" />

<p>令梯度为0，如果λ为正，解得β如下：</p>
<img src="./image-20211003201421768.png" alt="image-20211003201421768" style="zoom:50%;" />

<p>举个栗子：</p>
<img src="./image-20211003201643368.png" alt="image-20211003201643368" style="zoom:50%;" />

<h3 id="kernel-ridge-regression做classification-LSSVM-least-squares-SVM"><a href="#kernel-ridge-regression做classification-LSSVM-least-squares-SVM" class="headerlink" title="kernel ridge regression做classification-LSSVM(least-squares SVM)"></a>kernel ridge regression做classification-LSSVM(least-squares SVM)</h3><p>在基石课程中学习过regression可以用来做分类，那么kernel ridge regression也可以拿来做分类。这样做分类的方法叫做LSSVM。</p>
<blockquote>
<p>会玩，标准SVM中最大化margin进行分类，后来用到了LogReg上，再后来kernel+ridge regression，现在用从这条路去做分类了QAQ</p>
</blockquote>
<p>同一笔资料上使用soft-margin Gaussian SVM以及Gaussian LSSVM的效果对比如下：</p>
<img src="./image-20211008201159108.png" alt="image-20211008201159108" style="zoom:50%;" />

<p>可以看到边界几乎是一样的，左边的SV很少(标准SVM-&gt;对偶SVM-&gt;KKT条件中会保证α是稀疏的)，但是LSSVM这边的SV数量更多(因为LSSVM中的β是稠密的，此外在推理的时候，稠密的β意味着计算量大)。</p>
<p>那么有没有办法让β稀疏一些呢？下回分解。</p>
<h3 id="Tube-Regression"><a href="#Tube-Regression" class="headerlink" title="Tube Regression"></a>Tube Regression</h3><p>在回归的时候允许有ε的误差(“中立区”)，如果样本点落在中立区，不记错误，样本点落在中立区外边的时候，误差只记与中立区之间的距离。</p>
<p>在X是二维的时候，可以想象这确实很像个tube…</p>
<blockquote>
<p>注意，这里别和soft-margin SVM搞混了，现在是regression的问题，下图中的横轴是x，纵轴是y，蓝色的线是预测出来的线性模型，圆圈是真实的y。</p>
</blockquote>
<img src="./image-20211008202820997-16337082154092.png" alt="image-20211008202820997" style="zoom:50%;" />

<p>error measure如下，叫做<font color='orange'>ε-不敏感误差</font>，其中ε&gt;0:</p>
<img src="file://E:\blog\myblog\source\_posts\ML-techniques\image-20211008203728213.png?lastModify=1633708718" alt="image-20211008203728213" style="zoom:50%;" />

<p>tube error和squared error图示对比如下，可以看到当score≈y时，两者差距很小：</p>
<img src="./image-20211008204136981.png" alt="image-20211008204136981" style="zoom:50%;" />

<p>接下来要做的是加上L2正则，使用SVM中的解法，QP=&gt;解Dual=&gt;结合KKT条件尝试得到稀疏的β。</p>
<p><strong>加正则项：</strong></p>
<img src="./image-20211008204352302.png" alt="image-20211008204352302" style="zoom:50%;" />

<p>形式上为了和以前的SVM相近一些，使用SVM中惯用的C，并且将LinReg中的w0剥离出来成b。<font color='red'>至于为什么能把λ/N换成1/2，QAQ</font></p>
<img src="./image-20211008204915411.png" alt="image-20211008204915411" style="zoom:50%;" />

<p><strong>把max拆开，得到QP问题：</strong></p>
<p>为了拆开max部分，类似soft margin中的操作，引入ξn记录样本n犯的错误。</p>
<img src="./image-20211008212406227.png" alt="image-20211008212406227" style="zoom:50%;" />

<blockquote>
<p>这个式子看起来可能不是很直观，但是设想一个点在中立区，此时它犯的错误为0；如果这个点在中立区之外犯了错误，那么错误就是ξ</p>
</blockquote>
<p>接下来去绝对值，用ξ↑表示y-s&lt;ε+ξ部分的错误，ξ↓表示另一部分的错误：</p>
<img src="./image-20211008213140018.png" alt="image-20211008213140018" style="zoom:50%;" />

<p>至此就得到了一个QP问题，C依然作为margin和tube violation的tradeoff，此外相比原来接触到的SVM多了一个ε参数，表示“宽容度”。参数数量有2N+1+<img src="./image-20211008213713813.png" alt="image-20211008213713813" style="zoom:33%;" />，条件有4N个。这个问题叫做<font color='orange'>标准Support Vector Regression</font>问题。</p>
<p>如何去掉the ugly <img src="./image-20211008213713813.png" alt="image-20211008213713813" style="zoom:33%;" />?下回分解。</p>
<p><strong>解对偶问题：</strong></p>
<blockquote>
<p>过程暂时省略，先看结果</p>
</blockquote>
<p>L对w的偏微分是0：</p>
<img src="./image-20211009010034056.png" alt="image-20211009010034056" style="zoom:50%;" />

<p>L对b的偏微分是0：</p>
<img src="./image-20211009010110646.png" alt="image-20211009010110646" style="zoom:50%;" />

<p>complementary slackness：</p>
<img src="./image-20211009010144803.png" alt="image-20211009010144803" style="zoom:50%;" />

<hr>

<p>对偶条件的样子有迹可循：</p>
<p>先看下soft margin SVM的原始问题与对偶问题的关系：</p>
<img src="./image-20211009010527061.png" alt="image-20211009010527061" style="zoom:50%;" />

<p>再看SVR的Primal与Dual的关系：</p>
<img src="./image-20211009010902457.png" alt="image-20211009010902457" style="zoom:50%;" />

<p>至此，SVR Dual可以被QP程序解决。</p>
<p><strong>SVR的解是稀疏的吗？</strong></p>
<p>w是z的线性组合，问题是组合的系数什么时候是0。</p>
<p>使用complementary slackness的条件：</p>
<img src="./image-20211009010144803.png" alt="image-20211009010144803" style="zoom:50%;" />

<ul>
<li>对于严格再tube内的样本点，即<img src="./image-20211009011128205.png" alt="image-20211009011128205" style="zoom:50%;" />，没有犯错误，两个ξ都是0；根据上面的两个等式，两个α都是0，此时<font color='orange'>β是0</font></li>
<li>在tube外或者边界上的点是SV</li>
</ul>
<p>所以SVR的解中，β是稀疏的。</p>
<h3 id="Kernel模型总结"><a href="#Kernel模型总结" class="headerlink" title="Kernel模型总结"></a><font color='orange'>Kernel模型总结</font></h3><p>线性模型</p>
<blockquote>
<p>LIBLINEAR专注于解决末行的问题</p>
</blockquote>
<img src="./image-20211009012122892.png" alt="image-20211009012122892" style="zoom:50%;" />

<p>linear+kernel </p>
<blockquote>
<p>LIBSVM专注于解决末行的问题</p>
</blockquote>
<img src="./image-20211009012258703.png" alt="image-20211009012258703" style="zoom:50%;" />

<p>使用建议</p>
<blockquote>
<p>第一行的模型实际中很少使用，用对应的第二行替代；</p>
<p>第三行的模型实际中也很少使用(dense)，用对应的第四行替代</p>
</blockquote>
<img src="./image-20211009012451404.png" alt="image-20211009012451404" style="zoom:50%;" />

<h1 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a>Aggregation</h1><p>Roadmap:</p>
<img src="./image-20211004185435760.png" alt="image-20211004185435760" style="zoom:50%;" />

<h2 id="blending-amp-bagging"><a href="#blending-amp-bagging" class="headerlink" title="blending&amp;bagging"></a>blending&amp;bagging</h2><h3 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h3><p>多个hypothesis如何合在一起得到更好的表现？</p>
<ul>
<li><p>选择验证集上表现最好的那个</p>
<blockquote>
<p>注意，这种方式下一堆弱hypothesis中选不到好的，能不能使用一些弱hypothesis得到强的G呢？下面会介绍。</p>
</blockquote>
<img src="./image-20211003224507689.png" alt="image-20211003224507689" style="zoom:50%;" /></li>
<li><p>无差别地求和-Uniform blending**(blending&amp;bagging)**</p>
<img src="./image-20211003224522400.png" alt="image-20211003224522400" style="zoom:50%;" /></li>
<li><p>加权求和(包含上面两种)-Linear blending**(AdaBoost)**</p>
<img src="./image-20211003224630368.png" alt="image-20211003224630368" style="zoom:50%;" />

<p>如果αt就是判断某个g是否能在验证集中表现得最好，就对应第一种；<br>如果αt都是1，就对应第二种。</p>
</li>
<li><p>看条件，包含上面所有情形-stacking**(Decision Tree)**</p>
<img src="./image-20211003224753539.png" alt="image-20211003224753539" style="zoom:50%;" /></li>
</ul>
<h3 id="Uniform-blending"><a href="#Uniform-blending" class="headerlink" title="Uniform blending"></a>Uniform blending</h3><p>在有了很多g的情况下，如何组合？</p>
<p>二分类的情况下，对每个样本点，使用不同的g加加减减(如果每个g都相同，那么就没效果了)：</p>
<img src="./image-20211003230111096.png" alt="image-20211003230111096" style="zoom:50%;" />

<p>多分类的情况下，看哪个类别票最多</p>
<img src="./image-20211003230329499.png" alt="image-20211003230329499" style="zoom:50%;" />

<p>回归的情况下，对各个g给出的预测取平均</p>
<img src="./image-20211003230439799.png" alt="image-20211003230439799" style="zoom:50%;" />

<hr>
以回归为例，尝试分析为什么uniform blending可以提升组合后G的表现.

<p>为便于表述，先讨论特定的x，g(x)直接用g表示，G(x)用G表示。T个g平均的squared error与G的squared error的关系：</p>
<img src="./image-20211003231249907.png" alt="image-20211003231249907" style="zoom:50%;" />

<p>推广到所有的x，可以得到平均的Eout(g)与融合后Eout(G)的关系：</p>
<img src="./image-20211003231618809.png" alt="image-20211003231618809" style="zoom:50%;" />

<blockquote>
<p>Eout(G)比一堆g平均下来所得到的Eout(g)要小，换句话说，uniform blending得到的G会比随便选一个g的结果更好！</p>
</blockquote>
<p>每一轮都拿N笔资料过来使用演算法学一个g，做无限多次，G的极限记作<img src="./image-20211003232446892.png" alt="image-20211003232446892" style="zoom:40%;" /></p>
<img src="./image-20211003232543725.png" alt="image-20211003232543725" style="zoom:50%;" />

<p>物理上的解释：演算法的平均表现=每个g与共识的偏离(<strong>variance</strong>)+所有g的共识(<strong>bias</strong>)</p>
<h3 id="Linear-blending"><a href="#Linear-blending" class="headerlink" title="Linear blending"></a>Linear blending</h3><p>使用α对g做线性组合，不再是一票一值</p>
<img src="./image-20211003224630368.png" alt="image-20211003224630368" style="zoom:50%;" />

<p>如何设置α的值？好的α应该是可以让Ein最小的，如下：</p>
<blockquote>
<p>外层的1/N·Σ是计算每个点的平均error</p>
<p>内层的Σ是linear blenging，为了得到G</p>
<p>现在的任务是对α的最优化，找到使得下面式子取得最小值的α</p>
</blockquote>
<img src="./image-20211004010642234.png" alt="image-20211004010642234" style="zoom:50%;" />

<p>这个式子和LinReg+transformer很相似，可以把g看作一种<font color='orange'>转换</font>。<code>Linear Blending=LinModel+hypotheses as transforme+constraints</code></p>
<img src="./image-20211004011257974.png" alt="image-20211004011257974" style="zoom:50%;" />

<p>α有条件怎么办？能不能变成条件的？假设某个α是负的，那么它与对应的g加权时，<code>αg=|α|(-g)</code>，负的也没问题，可以想象成把这个g“反过来用”。所以下面的讨论中都是无条件的最优化问题。</p>
<p><strong>具体点，怎么实施Linear Blending呢？</strong></p>
<ol>
<li><p>使用Dtrain获得g-，使用g-将Dval中的资料做一个“<font color='orange'>转换</font>”<img src="./image-20211009134238847.png" alt="image-20211009134238847" style="zoom:50%;" /></p>
</li>
<li><p>解一个LinReg问题，找到一个最好的α</p>
<img src="./image-20211009134337821.png" alt="image-20211009134337821" style="zoom:50%;" /></li>
<li><p>回传G，这里使用的是g，不再是g-了</p>
<img src="./image-20211009134418837.png" alt="image-20211009134418837" style="zoom:50%;" /></li>
</ol>
<h3 id="Nonlinear-Any-blending-Stacking"><a href="#Nonlinear-Any-blending-Stacking" class="headerlink" title="(Nonlinear) Any blending/Stacking"></a>(Nonlinear) Any blending/Stacking</h3><p>使用各种想象得到的moedel得到<img src="./image-20211009134712508.png" alt="image-20211009134712508" style="zoom:40%;" />，可以做非线性的事</p>
<img src="./image-20211004151955734.png" alt="image-20211004151955734" style="zoom:50%;" />

<h3 id="Bootstrap-aggregating-Bagging"><a href="#Bootstrap-aggregating-Bagging" class="headerlink" title="Bootstrap aggregating(Bagging)"></a>Bootstrap aggregating(Bagging)</h3><blockquote>
<p>韦氏词典对bootstrap的<a target="_blank" rel="noopener" href="https://www.merriam-webster.com/dictionary/bootstrap">翻译</a>：</p>
<p>to promote or develop by initiative and effort with little or no assistance</p>
<p>关键时候还得看英英词典啊TAT</p>
</blockquote>
<p>前面的blending是基于有了一堆g的基础上的，怎样获得多样的g？</p>
<ul>
<li>不同的模型</li>
<li>同一个模型，不同的超参数</li>
<li>初始值的随机性</li>
<li><strong>Data的随机性(下面详细讨论这个)</strong></li>
</ul>
<p>能不能用同一份资料得到不同的副本？</p>
<p>bootstrap sample： 从样本集合中有放回地抽样。</p>
<img src="./image-20211004153458391.png" alt="image-20211004153458391" style="zoom:50%;" />

<h2 id="Adaptive-boosting"><a href="#Adaptive-boosting" class="headerlink" title="Adaptive boosting"></a><font color='orange'>Adaptive boosting</font></h2><p>一个有趣的演算法，在找g的时候强调犯过错的地方。</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li>blending:有一堆g在手中的时候，uniform/linear/nonlinear各种方法组合</li>
<li>bagging:手上还没有g的时候，使用bootstrap的方式得到不一样的资料，获得不一样的g</li>
<li><strong>能不能比bagging得到更不一样的假说？进而获得更好的G？</strong></li>
</ul>
<h3 id="Re-weighting-by-bootstrapping"><a href="#Re-weighting-by-bootstrapping" class="headerlink" title="Re-weighting by bootstrapping"></a>Re-weighting by bootstrapping</h3><p>将原始的资料D经过bootstrap抽样，得到Dt：</p>
<img src="./image-20211004160946226.png" alt="image-20211004160946226" style="zoom:50%;" />

<p>使用Dt去找g的时候，会在四笔资料上最小化Ein。Dt上的Ein可以有下面两种表达形式。</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"><img src="./image-20211004161345947.png" alt="image-20211004161345947" style="zoom:50%;" /></th>
<th align="center"><img src="./image-20211004161418673.png" alt="image-20211004161418673" style="zoom:50%;" /></th>
</tr>
</thead>
<tbody><tr>
<td align="center">Note</td>
<td align="center">朴素的想法<br>直接在Dt中计算犯的错误</td>
<td align="center">cool idea，依然在原始的D中计算<br>只是每笔资料是否参与计算或者计算多少次与前面的系数u有关。不同的u表示不同的bootstrapping</td>
</tr>
</tbody></table>
<p>对于不同的<em><strong>u</strong></em>，计算对应的Ein之后，通过最小化Ein即可得到一个对应的g。</p>
<p>如何改变<em><strong>u</strong></em>以获得差异较大的g？下面的部分属实精彩:-)</p>
<img src="./image-20211004162020605.png" alt="image-20211004162020605" style="zoom:50%;" />

<p>假设<code>u_t</code>加权的资料得到<code>g_t</code>，<code>u_t+1</code>加权的资料得到<code>g_t+1</code>，且<code>g_t</code>在<code>u_t+1</code>资料上表现得很差，那么也就是说在使用<code>u_t+1</code>资料计算对应的最好的假说时，不会再选到类似<code>g_t</code>的假说了。<font color='blue'>如果有办法让<code>g_t</code>在<code>u_t+1</code>资料上表现得很差</font>，就可以得到和<code>g_t</code>很不一样的<code>g_t+1</code>了。<font color='blue'>什么样的二元分类叫表现很差? <strong>分类的准确率接近0.5</strong></font>。</p>
<p>下面的目的就是通过精心设计的<code>u_t+1</code>在<code>g_t</code>上得到50%的准确率：</p>
<img src="./image-20211004163400603.png" alt="image-20211004163400603" style="zoom:50%;" />

<p>将样本点分为两类：<font color='orange'>犯错误的点</font>和<font color='green'>不犯错误的点</font>:</p>
<img src="./image-20211009142540184.png" alt="image-20211009142540184" style="zoom:50%;" />

<p><font color='orange'>犯错误的点</font>和<font color='green'>不犯错误的点</font>的数量调到一样就达到目的了。似乎很复杂，但其实只要对<code>u_t</code>做一个缩放就好了：</p>
<img src="./image-20211004164134313.png" alt="image-20211004164134313" style="zoom:50%;" />

<p>如果gt的错误率为εt，例如上表中的是1126/7337，那么在t+1时，要将错误的样本点按照正比于(1-εt)的比例缩放并取出，将正确的点按照正比于εt的比例缩放并取出。</p>
<img src="./image-20211009142945413.png" alt="image-20211009142945413" style="zoom:50%;" />

<h3 id="Adaptive-Boosting-AdaBoost-Algorithm"><a href="#Adaptive-Boosting-AdaBoost-Algorithm" class="headerlink" title="Adaptive Boosting(AdaBoost) Algorithm"></a>Adaptive Boosting(AdaBoost) Algorithm</h3><p>总结一下上一小节中的内容：</p>
<ol>
<li><p>先把gt的错误率计算出来</p>
<img src="./image-20211004165542571.png" alt="image-20211004165542571" style="zoom:50%;" /></li>
<li><p>将犯错的点做(1-εt)比例的放缩；正确的点做εt比例的放缩</p>
<img src="./image-20211004165716948.png" alt="image-20211004165716948" style="zoom:50%;" /></li>
<li><p>定义一个放缩系数♦t</p>
<img src="./image-20211004165854982.png" alt="image-20211004165854982" style="zoom:50%;" />

<p>新旧错误点/正确点的数量可以按照如下关系设置：</p>
<img src="./image-20211004165955437.png" alt="image-20211004165955437" style="zoom: 50%;" />

<blockquote>
<p>停下来看看♦与下一轮错误率的关系：</p>
<p>如果错误率不超过50%的话，♦是比1大的，那么下一轮要采的错误点会变多，正确点会减少。</p>
</blockquote>
</li>
</ol>
 <hr>
流程如下：

<img src="./image-20211004171000795.png" alt="image-20211004171000795" style="zoom:50%;" />

<p>这个流程还有两个问题：</p>
<ol>
<li><p>初始的u如何设置？</p>
<p>平等对待，u=1/N</p>
</li>
<li><p>得到了不同的g之后，最终如何组合出G？</p>
<p>uniform显然是不合适的了，因为目的本来就是让g在不对应的Dt上表现得很烂。可以考虑linear/non-linear等方式。</p>
</li>
</ol>
<p><strong>Next motivation</strong>:<font color='orange'>要是能在得到g的同时顺便知道应该如何组合就好了</font></p>
<p>好的g(ε小，♦大)的α应该大一些，例如可以使用一个单调函数，传入♦得到α。设计演算法的人选用的是ln(·)函数。</p>
<ul>
<li>εt=0.5时，表现很烂，♦=1，α=ln(♦)=0</li>
<li>εt→0时，表现很好，♦=∞，α=ln(♦)=∞</li>
</ul>
<hr>

<img src="./image-20211004172227793.png" alt="image-20211004172227793" style="zoom:50%;" />

<p>完整的AdaBoost流程如下：</p>
<img src="./image-20211004172345200.png" alt="image-20211004172345200" style="zoom:50%;" />

<hr>
**claim—AdaBoost在VC Bound上的理论保证：**

<img src="./image-20211004172508852.png" alt="image-20211004172508852" style="zoom:50%;" />

<p>原作者证明AdaBoost有下面的性质：</p>
<img src="./image-20211004172622732.png" alt="image-20211004172622732" style="zoom:50%;" />

<p>如果base演算法比乱猜的效果好，AdaBoost就可以越做越好，将Ein做到很小很小的时间复杂度是O(log N)。</p>
<h2 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h2><p>DT是很有用的模型，可解释性强，简单有效 QWQ</p>
<p>但是缺乏理论解释</p>
<img src="./image-20211004192621438.png" alt="image-20211004192621438" style="zoom:50%;" />

<h3 id="Decision-Tree-Hypothesis"><a href="#Decision-Tree-Hypothesis" class="headerlink" title="Decision Tree Hypothesis"></a>Decision Tree Hypothesis</h3><p>一个决策树就是一个G，其中包含判断的过程，也就是前面提到的<strong>conditional</strong>，那么怎样把Decision Tree拆解成g和条件q呢？ g就是末端的叶子节点，条件就是决策树的判断分支。</p>
<p>决策树的递归表示如下，把决策树拆分成<code>Σ(进树的条件·子树)</code></p>
<img src="./image-20211004192830433.png" alt="image-20211004192830433" style="zoom:50%;" />

<blockquote>
<p>G(x):full tree</p>
<p>b(x):branching criteria</p>
<p>Gc(x):sub-tree at c-th branch</p>
</blockquote>
<h3 id="A-Basic-Decision-Tree-Algorithm-CART"><a href="#A-Basic-Decision-Tree-Algorithm-CART" class="headerlink" title="A Basic Decision Tree Algorithm-CART"></a>A Basic Decision Tree Algorithm-CART</h3><p>给决策树演算法一笔资料，如何做分支？分几支？什么时候停？回传的g是什么？</p>
<img src="./image-20211004193246485.png" alt="image-20211004193246485" style="zoom:50%;" />

<p>本节介绍的是<strong>Classification and Regression Tree</strong>。CART中的设计如下：</p>
<ul>
<li><p>通过最小化不纯度做分支，希望<font color='orange'>纯度</font>越来越高</p>
<p>在分类的时候常常使用Gini指数；回归的时候常使用MSE</p>
</li>
</ul>
<ul>
<li>使用decision stump分两支</li>
<li>不纯度为0；或者分到无法再分(此时的树叫fully grown tree)</li>
<li>g是常数；在分类问题中表示类别，在回归问题中，是平均的y</li>
</ul>
<h3 id="CART中的Pruning"><a href="#CART中的Pruning" class="headerlink" title="CART中的Pruning"></a>CART中的Pruning</h3><p>使用树叶的数量衡量树的复杂度，作为正则项，在所有的树中找下面式子的最优解：</p>
<img src="./image-20211009153006501.png" alt="image-20211009153006501" style="zoom: 50%;" />

<p>但这并不是一个可行的方法，所以尝试换个思路，在完全生成树上移除一片叶子并计算移除后的Ein，最终移除那个使Ein最小的叶子；然后按照上述步骤依次移除更多的叶子，产生了很多树，在这些树中加正则并最小化。λ通过Dval选择。</p>
<h3 id="决策树中的代理分支"><a href="#决策树中的代理分支" class="headerlink" title="决策树中的代理分支"></a>决策树中的代理分支</h3><p>在训练的时候可以为属性找代理属性。代理属性在某条件下切分的数据与原始属性切分得到的几乎相同。</p>
<p>找到代理属性之后，在测试时遇到空缺的属性时，可以用代理属性替代。</p>
<h2 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h2><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p><strong><font color='orange'>Random Forest=bagging+decision tree</font></strong></p>
<p>bagging通过bootstrap的方式获得不一样的资料，得到不同的g，并投票得到G。bagging中通过投票的方式提高base algorithm稳定性；</p>
<p>decision tree中的切割会使得variance很大；</p>
<p>Random Forest做的就是将两者结合起来，aggregation of aggregation！</p>
<p>基本的RF流程如下，bagging的方式取资料，获得不同的decision tree，RF最终返回的G是uniform(decision tree)</p>
<img src="./image-20211005111220437.png" alt="image-抽取资料" style="zoom: 50%;" />

<hr>

<p>可以通过随机选取特征的方式增加决策的多样性：</p>
<img src="./image-20211005111419399.png" alt="image-20211005111419399" style="zoom:50%;" />

<h3 id="Out-Of-Bag-Data-amp-self-validation"><a href="#Out-Of-Bag-Data-amp-self-validation" class="headerlink" title="Out Of Bag Data &amp; self validation"></a>Out Of Bag Data &amp; self validation</h3><p>OOB data就是在某一次bootstrap资料时没被抽取到的资料。下表中，在获得每个g时，没有用到的资料用<font color='red'>*</font>表示。这些资料能发挥什么作用呢？</p>
<img src="./image-20211009160437556.png" alt="image-20211009160437556" style="zoom:50%;" />

<p>如果抽的数量和总的资料数量一样，大概会有1/3的资料没被抽到：</p>
<img src="./image-20211005112120424.png" alt="image-20211005112120424" style="zoom:50%;" />

<p>没有被抽到的资料就像是验证资料一样：</p>
<img src="./image-20211005112314951.png" alt="image-20211005112314951" style="zoom:50%;" />

<p>可以用OOB data验证g吗？—可以但是没必要，因为最后要的是G，即使g不好，最后的G也可能还不错。</p>
<p>可以用OOB data验证G吗？—可以，但是要慎重。每一笔资料被OOB的g(s)是不一样的，因此每一笔资料只能用于验证那些没用到它的g：</p>
<img src="./image-20211005112755313.png" alt="image-20211005112755313" style="zoom:50%;" />

<img src="./image-20211005112816380.png" alt="image-20211005112816380" style="zoom:50%;" />

<p>这种self validation的特性意味着不需要再将资料分成训练和验证两个部分，两者可以合在一起丢给RF。Eoob可以很好得衡量G的表现。</p>
<h3 id="random-test-amp-Feature-selection"><a href="#random-test-amp-Feature-selection" class="headerlink" title="random test&amp;Feature selection"></a>random test&amp;<font color='orange'>Feature selection</font></h3><blockquote>
<p>希望自动移除特征中冗余/无关的部分，降维。好用👍</p>
</blockquote>
<img src="./image-20211005113556277.png" alt="image-20211005113556277" style="zoom:50%;" />

<p>如果能够知道每个feature的重要性，那么选重要的那些特征就可以降维了：</p>
<ul>
<li>在linear model中，选绝对值大的w</li>
<li>non-linear中，random test👇</li>
</ul>
<p>如果某个特征是重要的， 那么给它加noise之后的表现会变差。</p>
<p>noise怎么加？对特征做排列(permutation)：</p>
<img src="./image-20211005113938452.png" alt="image-20211005113938452" style="zoom:50%;" />

<p>performance如何衡量？使用OOB error。</p>
<p>在原始的D上使用RF训<strong>练得</strong>到G；特征重新排列后的资料记为Dp，用RF<strong>训练</strong>得到Gp。Eoob(G)-Eoob(Gp)就是加了“噪声”之后造成的表现变差程度的度量。Gp有必要再训练一次吗？原作者表示，Eoob(Gp)可以用Eoob_p(G)近似替代。也就是在使用OOB资料验证的时候，重新排列特征。</p>
<h3 id="要用多少棵树？"><a href="#要用多少棵树？" class="headerlink" title="要用多少棵树？"></a>要用多少棵树？</h3><p>理论上是越多越好。</p>
<p>实际中看G是否稳定，增减树的数量，看performance。</p>
<h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><blockquote>
<p>todo❌</p>
<p>touda✔</p>
</blockquote>
<h1 id="隐含特征"><a href="#隐含特征" class="headerlink" title="隐含特征"></a>隐含特征</h1><h2 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h2><h3 id="从perceptron到MLP"><a href="#从perceptron到MLP" class="headerlink" title="从perceptron到MLP"></a>从perceptron到MLP</h3><p>多个感知机集成之后，G可以表示成下面左图的样子，图示如右图：</p>
<table>
<thead>
<tr>
<th align="center"><img src="./image-20211010123947967.png" alt="image-20211010123947967" style="zoom:50%;" /></th>
<th align="center"><img src="./image-20211010124337518.png" alt="image-20211010124337518" style="zoom:33%;" /></th>
</tr>
</thead>
</table>
<p>上面的模型可以实现一些运算，得到复杂的边界，以逻辑与为例：</p>
<img src="./image-20211010124919588.png" alt="image-20211010124919588" style="zoom:50%;" />

<p>下面左边是G的式子，右边是图示：</p>
<table>
<thead>
<tr>
<th align="center"><img src="./image-20211010124639641.png" alt="image-20211010124639641" style="zoom:50%;" /></th>
<th align="center"><img src="./image-20211010124655301.png" alt="image-20211010124655301" style="zoom: 50%;" /></th>
</tr>
</thead>
</table>
<p>上面的两层线性模型能实现异或运算吗？答案是不能。因为使用**<font color='red'>线性模型</font>**转换之后得不到线性可分的边界。</p>
<img src="./image-20211010125101108.png" alt="image-20211010125101108" style="zoom:50%;" />

<p>如果再加一层转换，就可以分开了，</p>
<img src="./image-20211010125402631.png" alt="image-20211010125402631" style="zoom: 50%;" />

<img src="./image-20211010125414821.png" alt="image-20211010125414821" style="zoom:50%;" />

<h3 id="NN-hypothesis"><a href="#NN-hypothesis" class="headerlink" title="NN hypothesis"></a>NN hypothesis</h3><p>到这里的时候再来思考一下NN的结构，可以看成是将输入的特征进行多次<strong>转换</strong>之后再聚合。</p>
<p>什么是转换？转换就是<em><strong>x</strong></em>与<em><strong>w</strong></em>的内积(也可以想象成一种编码)，而内积又表示向量之间的相似性，可以看作是“<strong>模式上的确认</strong>”，NN的每一层在做的就是<font color=orange>pattern extraction</font></p>
<p>转换函数就是之前听说过的激活函数，非线性的转换函数有名的比如tanh，logistic，ReLU…</p>
<p>NN hypothesis的结构如下：</p>
<img src="./image-20211010133623800.png" alt="image-20211010133623800" style="zoom:50%;" />

<blockquote>
<p>符号说明：</p>
<ul>
<li><p><em><strong>x</strong></em>的维度记为d</p>
</li>
<li><p>输入部分记作第0层，往后每经过一次处理层数上都加1</p>
</li>
<li><p>第m-1层到第m层的权重用<strong>W</strong>上标m表示，<strong>W</strong>中记录两层的节点之间的权重，例如wij表示前一层第i个节点(特征)到后一层第j个节点(特征)之间的权重</p>
</li>
<li><img src="./image-20211010132309170.png" alt="image-20211010132309170" style="zoom:50%;" /></li>
<li><img src="./image-20211010132325827.png" alt="image-20211010132325827" style="zoom:50%;" /></li>
</ul>
</blockquote>
<h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>以regression为例，如何最小化Ein？👇</p>
<img src="./image-20211010134733682.png" alt="image-20211010134733682" style="zoom:50%;" />

<p>经过很多层的转换之后，Ein很难再是Convex的，得到的g常常是local minima。</p>
<h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><p>NN的VC维：</p>
<img src="./image-20211006151940191.png" alt="image-20211006151940191" style="zoom:50%;" />

<p>节点数量越多、权值数量越多，VC维越大。所以需要警惕NN的overfitting。</p>
<p>正则的方式例如L2(weight-decay)：</p>
<img src="./image-20211010135831767.png" alt="image-20211010135831767" style="zoom:50%;" />

<p>scaled-L2(weight-elimination):</p>
<img src="./image-20211010140000723.png" alt="image-20211010140000723" style="zoom:50%;" />

<img src="./image-20211010140418290.png" alt="image-20211010140418290" style="zoom:67%;" />

<p>除了加正则项，还有early stopping的招式。w的更新次数越多，意味着选择范围越大，VC维也会随之增加。early stopping可以看成是一种减小VC维的方式。至于什么时候停，看Dval的表现。</p>
<h3 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h3><h3 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h3><p>deep的意义：提取的特征从简单到复杂。</p>
<p>challenge of deep learning：</p>
<ul>
<li>架构设计—domain knowledge</li>
<li>模型复杂度高—big data+regularization</li>
<li>优化—选good初始值(pre-training)</li>
<li>计算复杂度高—GPU</li>
</ul>
<h3 id="AutoEncoder-unsupervised-learning"><a href="#AutoEncoder-unsupervised-learning" class="headerlink" title="AutoEncoder-unsupervised learning"></a>AutoEncoder-unsupervised learning</h3><p>good weight是在转换后能轻易重建转换前特征的那些特征。</p>
<p>AutoEncoder做的就是找information-preserving的<em><strong>w</strong></em>。</p>
<img src="./image-20211010143126485.png" alt="image-20211010143126485" style="zoom:50%;" />

<p>几个说明：</p>
<ul>
<li>AutoEncoder的网络很浅，方便训练</li>
<li>常常考虑的是中间层的特征比输入少的情况，用于压缩</li>
<li>这时一种非监督式的学习</li>
<li>一种正则化的方式：encoder的权重和decoder的权重一样<font color='red'>?????</font></li>
</ul>
<h3 id="Regularization-in-DL"><a href="#Regularization-in-DL" class="headerlink" title="Regularization in DL"></a>Regularization in DL</h3><ul>
<li><p>结构上的限制</p>
</li>
<li><p>early stopping</p>
</li>
<li><p>weight decay</p>
</li>
<li><p>加噪</p>
<p>以AutoEncoder为例：</p>
<img src="./image-20211010144423170.png" alt="image-20211010144423170" style="zoom:50%;" /></li>
</ul>
<h3 id="linear-AutoEncoder-amp-PCA"><a href="#linear-AutoEncoder-amp-PCA" class="headerlink" title="linear AutoEncoder&amp;PCA"></a>linear AutoEncoder&amp;PCA</h3><h4 id="linear-AutoEncoder"><a href="#linear-AutoEncoder" class="headerlink" title="linear AutoEncoder"></a>linear AutoEncoder</h4><p>线性的AutoEncoder长什么样子？</p>
<img src="./image-20211010145207624.png" alt="image-20211010145207624" style="zoom:50%;" />

<p>为了便于讨论：</p>
<ol>
<li>不看x0(输入与输出的维度就相同了)</li>
<li>加正则项：编码权重=解码权重。编码用<strong>W</strong>表示，解码用<strong>W</strong>^T表示</li>
</ol>
<p>最终的hypothesis如下：</p>
<img src="./image-20211010145236721.png" alt="image-20211010145236721" style="zoom:50%;" />

<p>矩阵形式：</p>
<img src="./image-20211010145430305.png" alt="image-20211010145430305" style="zoom:50%;" />

<p>Ein如下，使用MSE衡量误差：</p>
<img src="./image-20211010145543777.png" alt="image-20211010145543777" style="zoom:50%;" />

<p>接下来要做的是得到minEin的公式解。</p>
<p>WW^T是一个半正定的矩阵，可以先做个特征值分解：</p>
<img src="./image-20211010145933253.png" alt="image-20211010145933253" style="zoom:50%;" />

<p>线性代数告诉我们：</p>
<ol>
<li>V是正交的，即<img src="./image-20211010150105645.png" alt="image-20211010150105645" style="zoom:50%;" /></li>
<li>Γ是个对角阵，且每个特征值都是非负的。由于<strong>W</strong>的维度是<img src="./image-20211010150331175.png" alt="image-20211010150331175" style="zoom:50%;" />，且要做的是压缩，所以rank(<strong>W</strong>)&lt;<img src="./image-20211008213713813.png" alt="image-20211010150405959" style="zoom:50%;" />，所以Γ的对角线上非零的数最多有<img src="./image-20211008213713813.png" alt="image-20211010150521265" style="zoom:50%;" />个。</li>
</ol>
<p>结合特征值分解的式子，原来的假说可以写成下面的样子：</p>
<img src="./image-20211010150700812.png" alt="image-20211010150700812" style="zoom:50%;" />

<p>如何理解？</p>
<ul>
<li><p><em><strong>x</strong></em>和一个正交阵相乘，表示一种rotate或者reflect的坐标转换；</p>
</li>
<li><p>转换之后乘Γ，而Γ中至少有<img src="./image-20211010150907777.png" alt="image-20211010150907777" style="zoom:50%;" />个0，意味着会把上面转换后的值涂掉一部分，放缩一部分；</p>
</li>
<li><p>最后再乘V，表示再做一次坐标转换，变换到原来的坐标系。</p>
</li>
</ul>
<p>Ein中的x为了形式上统一，写成下面的样子：</p>
<img src="./image-20211010151312584.png" alt="image-20211010151312584" style="zoom:50%;" />

<p>铺垫完毕，接下来把对W的最优化问题变成对V和Γ的最优化问题。</p>
<hr>

<p>先从Γ开始：</p>
<img src="./image-20211010151437575.png" alt="image-20211010151437575" style="zoom:50%;" />

<p>V是正交阵，是一种rotate或者reflect的变换，不影响长度，所以直接不考虑V，内部对Γ的最优化问题变成了：</p>
<img src="./image-20211010151736941.png" alt="image-20211010151736941" style="zoom:50%;" />

<p>如果I-Γ中有够多的0就好了，换句话说，希望Γ的对角线上有很多个1。最多有多少个？最多有<img src="./image-20211008213713813.png" alt="image-20211010152114738" style="zoom:50%;" />个。最佳的Γ形如下面：</p>
<img src="./image-20211010152220339.png" alt="image-20211010152220339" style="zoom:50%;" />

<p>下面看V的部分：</p>
<img src="./image-20211010152248279.png" alt="image-20211010152248279" style="zoom:50%;" />

<p>为了形式上看起来更干净，解另一个和它一样的问题</p>
<blockquote>
<p>左边表示留下来越少越好，右边表示扔掉越多越好。</p>
</blockquote>
<img src="./image-20211010152637257.png" alt="image-20211010152637257" style="zoom:50%;" />

<p>如果<img src="./image-20211010152114738.png" alt="image-20211010152654239" style="zoom:50%;" />=1，最优化的问题就成了：如何让(V^T)xn的第一列最大？</p>
<img src="./image-20211010153203553.png" alt="image-20211010153203553" style="zoom:50%;" />

<p>这是个有条件的最优化问题，使用lagrange函数，一顿操作之后得到最优的<em><strong>v</strong></em>下面的条件，其中λ是乘子：</p>
<img src="./image-20211010153424575.png" alt="image-20211010153424575" style="zoom: 50%;" />

<p>这式子是什么意思？</p>
<table>
<thead>
<tr>
<th align="center">矩阵·<em><strong>v</strong></em>=数·<em><strong>v</strong></em></th>
</tr>
</thead>
</table>
<p>意思就是：最好的<em><strong>v</strong></em>是(X^T)X的特征向量，且可以证明，应该是最大的特征向量。那么要求<strong>V</strong>的第一列是对应最大特征值的特征向量。</p>
<blockquote>
<p><font color='red'>上面图里绿色的部分是(X^T)X吗 QWQ</font></p>
</blockquote>
<p><font color='red'><strong>V</strong>也解出来了，最好的<strong>W</strong>是什么？</font>👇</p>
<img src="./image-20211010161603389.png" alt="image-20211010161603389" style="zoom:50%;" />

<h4 id="PCA-more-popular"><a href="#PCA-more-popular" class="headerlink" title="PCA(more popular)"></a>PCA(more popular)</h4><p>上面最大化的是投影后的强度之和，PCA最大化的是投影后的变化量(与平均之间的偏离)之和。</p>
<p>如何使用linear Encoder做PCA？</p>
<ol>
<li>先把资料做变换：减去平均值</li>
<li>做linear AutoEncoder，得到<strong>W</strong></li>
<li>在有新的资料过来的时候，先减去平均，再做<strong>W</strong>的变换</li>
</ol>
<p>但事实上，PCA比linear AutoEncoder更popular</p>
<h2 id="RBF-Network"><a href="#RBF-Network" class="headerlink" title="RBF Network"></a>RBF Network</h2><h3 id="RBF-hypothesis"><a href="#RBF-hypothesis" class="headerlink" title="RBF hypothesis"></a>RBF hypothesis</h3><p>回顾一下Gaussian SVM</p>
<img src="./image-20211010161958941.png" alt="image-20211010161958941" style="zoom:50%;" />

<p>可以看成是在SV上使用α对basis function(在这里是高斯函数)的线性组合。</p>
<p>RBF Network做的就是radial hypotheses的线性组合，即距离+Gaussian；而NN做的是内积+非线性激活：</p>
<img src="./image-20211010162401608.png" alt="image-20211010162401608" style="zoom:50%;" />

<p>一般地，RBF的hypothesis如下：</p>
<img src="./image-20211010163046766.png" alt="image-20211010163046766" style="zoom:50%;" />

<p>给定RBF的样子以及输出的方式，要确定的是中心在哪，以及线性组合的系数是什么。</p>
<h3 id="RBF-Network-learning"><a href="#RBF-Network-learning" class="headerlink" title="RBF Network learning"></a>RBF Network learning</h3><p>RBF的中心点怎么找？</p>
<h4 id="Full-RBF-amp-Nearest-Neighbor"><a href="#Full-RBF-amp-Nearest-Neighbor" class="headerlink" title="Full RBF&amp;Nearest Neighbor"></a>Full RBF&amp;Nearest Neighbor</h4><p>Full RBF把所有看过的资料点都当作中心。N笔资料就有N个中心，于是M=N。</p>
<p>举个例子，令加权的系数β为对应的标签：</p>
<img src="./image-20211010164546334.png" alt="image-20211010164546334" style="zoom:50%;" />

<p>Radial function衰减得很快，与新的x最接近的那个样本将给出最大的输出，所以这个点是Σ部分的主导部分。那么只要找到距离新的样本点x<strong>最近</strong>的样本就好了(Nearest Neighbor Model)。结果会是这样：新x的sign将和距离最近的样本点的sign一致：</p>
<img src="./image-20211010180913446.png" alt="image-20211010180913446" style="zoom:50%;" />

<p>但这种方法做下去就不能叫aggregation，而是selection。</p>
<p>使用full RBF做regression的话，就是对RBF变换后的资料的线性回归：</p>
<img src="./image-20211010170831208.png" alt="image-20211010170831208" style="zoom:50%;" />

<p>RBF的变换用矩阵Z表示：</p>
<img src="./image-20211010170645590.png" alt="image-20211010170645590" style="zoom:50%;" />

<p>最好的β有封闭解。可以证明(P55)，这样做出来的Ein是0，有overfitting的风险。加正则项！</p>
<p>首先是ridge regression，得到的β如下：   </p>
<img src="./image-20211010170439560.png" alt="image-20211010170439560" style="zoom:50%;" />

<p>下面尝试少用一些点(M&lt;&lt;N)得到regularization的效果、如何找到一些有代表的点？下回分解。</p>
<h3 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h3><p>将样本点分成M个群，每个点属于一个群。cluster error描述如下，最小化各个点到自己的群代表的距离：</p>
<img src="./image-20211010182224020.png" alt="image-20211010182224020" style="zoom:50%;" />

<p>·有两组变量，这里采用的方法是optimize alternatively。</p>
<ul>
<li>固定中心点，选每个样本的群</li>
<li>固定每个群，计算群的中心点</li>
</ul>
<h3 id="k-means-RBF"><a href="#k-means-RBF" class="headerlink" title="k-means+RBF"></a>k-means+RBF</h3><p>使用非监督学习帮助特征转换</p>
<img src="./image-20211010183056496.png" alt="image-20211010183056496" style="zoom:50%;" />

<h2 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h2><p>更加抽象的input feature，例如类别特征。但是以往学过的模型中，除了决策树及其延伸可以处理类别特征外，其他的模型都只吃数值特征。</p>
<p>本节从一个实例出发， 讨论的是如何将类别特征转成数值特征(encoding)，并使用转换后的特征进行学习。</p>
<hr>

<p>手上有的资料是不同用户对不同电影的评分，要预测的是用户对没有看过的电影的评分。</p>
<p>资料的样子是这样：对于第m部电影，第n个用户的评分是rnm，那么Dm如下：</p>
<img src="./image-20211010203655217.png" alt="image-20211010203655217" style="zoom:50%;" />

<p>x是用户的编号，是抽象的特征，没有数值上的意义，只有类别的意义，叫做类别特征。</p>
<p><strong>第一步</strong>，特征转换，把类别特征转成数值特征。一种非常简单的编码方式是binary vector encoding。编码之后资料的样子是这样：</p>
<img src="./image-20211010204158861.png" alt="image-20211010204158861" style="zoom:50%;" />

<p>把资料整合一下，对于每个用户(一串编码)，都用一个向量表示ta对诸多电影的评分</p>
<img src="./image-20211010204359506.png" alt="image-20211010204359506" style="zoom:50%;" />

<p><strong>第二步</strong>，特征抽取by NN。输入是对每个用户编码后的向量，只有一个维度是1，输出是对N部电影的评分。中间没有使用tanh转换。</p>
<img src="./image-20211010204849506.png" alt="image-20211010204849506" style="zoom:50%;" />

<p>为了表述方便，第一层的权重用<strong>V</strong>^T表示，第二层的权重用<strong>W</strong>表示</p>
<img src="./image-20211010205009152.png" alt="image-20211010205009152" style="zoom:50%;" />

<p>于是hypothesis可以写成下面的样子：</p>
<img src="./image-20211010205602421.png" alt="image-20211010205602421" style="zoom:50%;" />

<p>对于n号用户，<strong>x</strong>只有一个位置为1，V·x可以看成是一种特征转换Φ，作用就是取出V的第n列，记为<em><strong>vn</strong></em>。</p>
<p>对于第m部电影，它的预测得分是：</p>
<img src="./image-20211010205828741.png" alt="image-20211010205828741" style="zoom:50%;" />

<p><strong>第三步</strong>：Ein</p>
<p>想要的是对于每一部电影， 实际的评分和预测的评分越接近越好，于是Ein可以使用MSE表示：</p>
<img src="./image-20211010210121573.png" alt="image-20211010210121573" style="zoom:50%;" />

<blockquote>
<p>最小化这个Ein还能怎么理解呢？其实就是希望把评分矩阵分解成两个矩阵的乘积：</p>
<img src="./image-20211010210437894.png" alt="image-20211010210437894" style="zoom:50%;" />

<p>AutoEncoder中其实也有矩阵分解的含义：</p>
<img src="./image-20211010211123750.png" alt="image-20211010211123750" style="zoom:50%;" />
</blockquote>
<p>Ein中有两组变量，第一种方式是alternating minimization(P59) </p>
<img src="./image-20211010210619242.png" alt="image-20211010210619242" style="zoom:50%;" />

<img src="./image-20211010210928120.png" alt="image-20211010210928120" style="zoom:50%;" />

<p>第二种方式是SGD(P60)</p>
<img src="./image-20211010211359352.png" alt="image-20211010211359352" style="zoom:50%;" />

<h1 id="Finale"><a href="#Finale" class="headerlink" title="Finale"></a>Finale</h1><h2 id="feature-exploitation-techniques"><a href="#feature-exploitation-techniques" class="headerlink" title="feature exploitation techniques"></a>feature exploitation techniques</h2><p>核变换：kernel+linear model=&gt;non-linear model</p>
<p>集成学习</p>
<p>find hidden feature (possibly **with the  help of <font color='orange'>unsupervised learning</font> **)</p>
<p>降维</p>
<h2 id="error-optimization-techniques"><a href="#error-optimization-techniques" class="headerlink" title="error optimization techniques"></a>error optimization techniques</h2><p>梯度下降相关：</p>
<blockquote>
<p>GD一次逼近，牛顿法二次逼近 </p>
</blockquote>
<img src="./image-20211010194441711.png" alt="image-20211010194441711" style="zoom:50%;" />

<p>问题转化：</p>
<blockquote>
<p>Math warning！</p>
</blockquote>
<img src="./image-20211010194914623.png" alt="image-20211010194914623" style="zoom:50%;" />

<p>子问题：</p>
<img src="./image-20211010195812289.png" alt="image-20211010195812289" style="zoom:50%;" />

<h2 id="overfitting-eliminating-techniques"><a href="#overfitting-eliminating-techniques" class="headerlink" title="overfitting eliminating techniques"></a>overfitting eliminating techniques</h2><p>good feature+good optimization method=&gt;small Ein</p>
<p>“刹车保命”：</p>
<img src="./image-20211010200902181.png" alt="image-20211010200902181" style="zoom:50%;" />

<p>“看仪表板”：</p>
<img src="./image-20211010201011512.png" alt="image-20211010201011512" style="zoom:50%;" />

<h2 id="Machine-learning-in-practice"><a href="#Machine-learning-in-practice" class="headerlink" title="Machine learning in practice"></a>Machine learning in practice</h2><img src="./image-20211010201807369.png" alt="image-20211010201807369" style="zoom:50%;" />


    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/09/23/ML-Foundations/" rel="prev" title="机器学习基石">
                  <i class="fa fa-chevron-left"></i> 机器学习基石
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">movice</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
